{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Hack My Ride â€“ Data Preprocessing\n",
    "**Group members:**\n",
    "* Andrieux, Nicolas\n",
    "* Gjini, Jurgen\n",
    "* Hioco, Tomasso\n",
    "* Pypaert, Virgile\n",
    "\n",
    "As the project contains many different data sources and that some treatments are very similar between the questions, we decided to provide a Jupyter Notebook per question we answered to for the sake of clarity.\n",
    "\n",
    "The first part, in this file, contains all the data preprocessing we made on the datasets used in the various questions :\n",
    "- Vehicle positions ;\n",
    "- GTFS files ;\n",
    "- Shapefiles ;\n",
    "- GPS tracks by Mahmoud and Jean-Philippe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python packages import\n",
    "Here below are all the libraries that are necessary to the data preprocessing from cleaning to representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pyproj\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import gtfs_functions as gtfs\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from shapely.geometry import LineString\n",
    "from shapely.ops import transform\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable warnings about future superseded functions\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working directories\n",
    "As we all have different folder structure, you can provide below the path to the various files we are using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehiclePosition_folder = 'data/'\n",
    "gtfs_file = 'gtfs23Sept.zip'\n",
    "gpstracks_file = 'GPStracks.csv'\n",
    "shapefile_stops = 'shapefiles/ACTU_STOPS.shp'\n",
    "shapefile_lines = 'shapefiles/ACTU_LINES.shp'\n",
    "\n",
    "# Folder to export CSV when they have been treated and temporary folder when extracting ZIP files\n",
    "export_folder = 'export/'\n",
    "temporary_folder = 'temp/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "#### Vehicle positions\n",
    "The first operation consists in flattening and merging the files in order to obtain a single 5-columns Pandas dataframe. This is done using the functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the list of JSON files contained in the current folder\n",
    "fileList = []\n",
    "for file in os.listdir(vehiclePosition_folder):\n",
    "    if file.endswith('.json'):\n",
    "        fileList.append(vehiclePosition_folder + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data/vehiclePosition01.json\n",
      "Processing data/vehiclePosition02.json\n",
      "Processing data/vehiclePosition03.json\n",
      "Processing data/vehiclePosition04.json\n",
      "Processing data/vehiclePosition05.json\n",
      "Processing data/vehiclePosition06.json\n",
      "Processing data/vehiclePosition07.json\n",
      "Processing data/vehiclePosition08.json\n",
      "Processing data/vehiclePosition09.json\n",
      "Processing data/vehiclePosition10.json\n",
      "Processing data/vehiclePosition11.json\n",
      "Processing data/vehiclePosition12.json\n",
      "Processing data/vehiclePosition13.json\n",
      "Finished !\n"
     ]
    }
   ],
   "source": [
    "positionsList = []\n",
    "\n",
    "# Load the content from all the files\n",
    "for currentFile in fileList:\n",
    "    print(f'Processing {currentFile}')\n",
    "    # Read the file\n",
    "    f = open(currentFile)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Process the content of the file\n",
    "    for d in data['data']:\n",
    "        for line in d['Responses']:\n",
    "            if line is not None:\n",
    "                for l in line['lines']:\n",
    "                    for pos in l['vehiclePositions']:\n",
    "                        d_time = d['time']\n",
    "                        l_lineId = l['lineId']\n",
    "                        pos_directionId = pos['directionId']\n",
    "                        pos_pointId = pos['pointId']\n",
    "                        pos_distanceFromPoint = pos['distanceFromPoint']\n",
    "                        \n",
    "                        positionsList.append([d_time, l_lineId, pos_directionId, pos_pointId, pos_distanceFromPoint])\n",
    "\n",
    "# Merge all subdataframes into a single Pandas DF\n",
    "positions_df = pd.DataFrame(positionsList, columns=['time', 'lineId', 'directionId', 'pointId', 'distanceFromPoint'])\n",
    "\n",
    "# Divide the timestamp by 1000 as it is counted in ms\n",
    "positions_df = positions_df.astype({'time': 'int64'})\n",
    "positions_df['time'] = positions_df['time'].floordiv(1000)\n",
    "\n",
    "print(f'Finished !')\n",
    "\n",
    "# Delete the collection object to free RAM\n",
    "del positionsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the merged vehicle position dataframe\n",
    "#positions_df.to_csv(export_folder + 'mergedVehiclePosition.csv', index=False)\n",
    "# Load a copy of the merged vehicle position dataframe to avoid reprocessing each time\n",
    "positions_df = pd.read_csv(export_folder + 'mergedVehiclePosition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Line segments\n",
    "In analogy to graph theory, we can define a bus line as a graph with each stop being a node and each segment representing an edge between a couple of stops.\n",
    "\n",
    "We use the segments in order to obtain the distance between the different stops to calculate the average speed afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the information stored in the GTFS file\n",
    "routes, stops, stop_times, trips, shapes = gtfs.import_gtfs('gtfs3Sept.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Geodataframe for all the segments obtained from GTFS file\n",
    "segments_gdf = gtfs.cut_gtfs(stop_times, stops, shapes)\n",
    "\n",
    "# Extract information from other columns\n",
    "segments_gdf['Code_Ligne'] = segments_gdf['shape_id'].str[:4]\n",
    "segments_gdf['lineId'] = segments_gdf['shape_id'].str[:3]\n",
    "segments_gdf['mode'] = segments_gdf['shape_id'].str[3:4]\n",
    "segments_gdf['mode'] = segments_gdf['mode'].str.upper()\n",
    "\n",
    "segments_gdf['start_stop_id'] = segments_gdf['start_stop_id'].str[:4]\n",
    "segments_gdf['end_stop_id'] = segments_gdf['end_stop_id'].str[:4]\n",
    "\n",
    "# Rename columns\n",
    "segments_gdf = segments_gdf.rename(columns={\"direction_id\": \"Variante\", \"stop_sequence\": \"succession\"})\n",
    "\n",
    "# Cast the type\n",
    "segments_gdf = segments_gdf.astype({'lineId': 'int', 'start_stop_id': 'int', 'end_stop_id': 'int'})\n",
    "segments_gdf = segments_gdf.round({'distance_m' : 2})\n",
    "\n",
    "# Select columns\n",
    "segments_gdf = segments_gdf[[\"Code_Ligne\", \"lineId\", \"mode\", \"Variante\", \"succession\", \"start_stop_id\", \"end_stop_id\", \"distance_m\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>start_stop_name</th>\n",
       "      <th>end_stop_name</th>\n",
       "      <th>start_stop_id</th>\n",
       "      <th>end_stop_id</th>\n",
       "      <th>segment_id</th>\n",
       "      <th>shape_id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>distance_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>STOCKEL</td>\n",
       "      <td>CRAINHEM</td>\n",
       "      <td>8161</td>\n",
       "      <td>8151</td>\n",
       "      <td>8161-8151</td>\n",
       "      <td>001m0042</td>\n",
       "      <td>LINESTRING (4.46454 50.84187, 4.46361 50.84327...</td>\n",
       "      <td>876.832431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>CRAINHEM</td>\n",
       "      <td>ALMA</td>\n",
       "      <td>8151</td>\n",
       "      <td>8141</td>\n",
       "      <td>8151-8141</td>\n",
       "      <td>001m0042</td>\n",
       "      <td>LINESTRING (4.45872 50.84880, 4.45865 50.84888...</td>\n",
       "      <td>514.285249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ALMA</td>\n",
       "      <td>VANDERVELDE</td>\n",
       "      <td>8141</td>\n",
       "      <td>8131</td>\n",
       "      <td>8141-8131</td>\n",
       "      <td>001m0042</td>\n",
       "      <td>LINESTRING (4.45315 50.84988, 4.45133 50.84880...</td>\n",
       "      <td>545.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>VANDERVELDE</td>\n",
       "      <td>ROODEBEEK</td>\n",
       "      <td>8131</td>\n",
       "      <td>8121</td>\n",
       "      <td>8131-8121</td>\n",
       "      <td>001m0042</td>\n",
       "      <td>LINESTRING (4.44670 50.84739, 4.44541 50.84721...</td>\n",
       "      <td>799.287745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>ROODEBEEK</td>\n",
       "      <td>TOMBERG</td>\n",
       "      <td>8121</td>\n",
       "      <td>8111</td>\n",
       "      <td>8121-8111</td>\n",
       "      <td>001m0042</td>\n",
       "      <td>LINESTRING (4.43566 50.84753, 4.43476 50.84743...</td>\n",
       "      <td>827.451879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  route_id  direction_id  stop_sequence start_stop_name end_stop_name  \\\n",
       "0        2             1              1         STOCKEL      CRAINHEM   \n",
       "1        2             1              2        CRAINHEM          ALMA   \n",
       "2        2             1              3            ALMA   VANDERVELDE   \n",
       "3        2             1              4     VANDERVELDE     ROODEBEEK   \n",
       "4        2             1              5       ROODEBEEK       TOMBERG   \n",
       "\n",
       "  start_stop_id end_stop_id segment_id  shape_id  \\\n",
       "0          8161        8151  8161-8151  001m0042   \n",
       "1          8151        8141  8151-8141  001m0042   \n",
       "2          8141        8131  8141-8131  001m0042   \n",
       "3          8131        8121  8131-8121  001m0042   \n",
       "4          8121        8111  8121-8111  001m0042   \n",
       "\n",
       "                                            geometry  distance_m  \n",
       "0  LINESTRING (4.46454 50.84187, 4.46361 50.84327...  876.832431  \n",
       "1  LINESTRING (4.45872 50.84880, 4.45865 50.84888...  514.285249  \n",
       "2  LINESTRING (4.45315 50.84988, 4.45133 50.84880...  545.002721  \n",
       "3  LINESTRING (4.44670 50.84739, 4.44541 50.84721...  799.287745  \n",
       "4  LINESTRING (4.43566 50.84753, 4.43476 50.84743...  827.451879  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_gdf = gtfs.cut_gtfs(stop_times, stops, shapes)\n",
    "segments_gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code_Ligne</th>\n",
       "      <th>lineId</th>\n",
       "      <th>mode</th>\n",
       "      <th>Variante</th>\n",
       "      <th>succession</th>\n",
       "      <th>start_stop_id</th>\n",
       "      <th>end_stop_id</th>\n",
       "      <th>distance_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001m</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8161</td>\n",
       "      <td>8151</td>\n",
       "      <td>876.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001m</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8151</td>\n",
       "      <td>8141</td>\n",
       "      <td>514.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001m</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8141</td>\n",
       "      <td>8131</td>\n",
       "      <td>545.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>001m</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8131</td>\n",
       "      <td>8121</td>\n",
       "      <td>799.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001m</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8121</td>\n",
       "      <td>8111</td>\n",
       "      <td>827.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Code_Ligne  lineId mode  Variante  succession  start_stop_id  end_stop_id  \\\n",
       "0       001m       1    M         1           1           8161         8151   \n",
       "1       001m       1    M         1           2           8151         8141   \n",
       "2       001m       1    M         1           3           8141         8131   \n",
       "3       001m       1    M         1           4           8131         8121   \n",
       "4       001m       1    M         1           5           8121         8111   \n",
       "\n",
       "   distance_m  \n",
       "0      876.83  \n",
       "1      514.29  \n",
       "2      545.00  \n",
       "3      799.29  \n",
       "4      827.45  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the segments geodataframe\n",
    "#segments_gdf.to_csv(export_folder + 'segments.csv', index=False)\n",
    "# Load a copy of the segments geodataframe to avoid reprocessing each time\n",
    "segments_gdf = pd.read_csv(export_folder + 'segments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ID-Stops Conversion\n",
    "The dataset provided contains sometimes distinctions relative to the stop point (the platform, the direction, etc.) we need to be capable of converting between the ID and the stop name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a conversion table between ID and generic label\n",
    "IDStops = stops\n",
    "IDStops['stop_id'] = IDStops['stop_id'].str[:4]\n",
    "IDStops = IDStops.astype({'stop_id': 'int16'})\n",
    "IDStops = IDStops[['stop_id', 'stop_name']]\n",
    "IDStops.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the stops-ID conversion table\n",
    "#IDStops.to_csv(export_folder + 'IDstops.csv', index=False)\n",
    "# Load a copy of the stops-ID conversion table to avoid reprocessing each time\n",
    "IDStops = pd.read_csv(export_folder + 'IDstops.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing lines\n",
    "The goal here is to import data relative to lines and their stops and process them to be used afterwards for filtering relevant stops on a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare the dataframe of stops belonging to the different lines and variants\n",
    "linestops_df = gpd.read_file(shapefile_stops)\n",
    "linestops_df = linestops_df.to_crs(epsg=4326)\n",
    "\n",
    "# Extract information from other columns\n",
    "linestops_df['stop_id'] = linestops_df['stop_id'].str[:4]\n",
    "linestops_df['lineId'] = linestops_df['Code_Ligne'].str[:3]\n",
    "\n",
    "# Cast the type\n",
    "linestops_df = linestops_df.astype({'stop_id': 'int', 'lineId': 'int'})\n",
    "\n",
    "# Select columns and remove duplicates\n",
    "linestops_df = linestops_df[[\"stop_id\", \"lineId\", \"mode\", \"Variante\", \"succession\", \"descr_fr\", \"geometry\"]]\n",
    "linestops_df = linestops_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the processed linestops dataframe\n",
    "#linestops_df.to_csv(export_folder + 'linestops.csv', index=False)\n",
    "# Load a copy of the processed linestops dataframe to avoid reprocessing each time\n",
    "linestops_df = pd.read_csv(export_folder + 'linestops.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generalizing segments\n",
    "This consists of several successive steps:\n",
    "* Transforming IDs to stop name\n",
    "* Removing unused columns\n",
    "* Dropping duplicates\n",
    "\n",
    "After these operations, we obtain a dataframe that contains segments between source and end points for a specific line variant. This will be used to obtain the distance between two stops on a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with all the segments belonging to all the lines\n",
    "reworkedSegments = segments_gdf.merge(IDStops, left_on=['start_stop_id'], right_on=['stop_id'], how='left')\n",
    "reworkedSegments.rename(columns={'stop_name' : 'start_stop_name'}, inplace=True)\n",
    "reworkedSegments = reworkedSegments.merge(IDStops, left_on=['end_stop_id'], right_on=['stop_id'], how='left')\n",
    "reworkedSegments.rename(columns={'stop_name' : 'end_stop_name'}, inplace=True)\n",
    "\n",
    "# Drop superseded columns \n",
    "reworkedSegments.drop(columns=['stop_id_x', 'stop_id_y', 'Code_Ligne', 'mode', 'start_stop_id', 'end_stop_id', 'succession'], inplace=True)\n",
    "\n",
    "# Drop duplicates\n",
    "reworkedSegments.drop_duplicates(['lineId', 'Variante', 'start_stop_name', 'end_stop_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the reworked segments dataframe\n",
    "#reworkedSegments.to_csv(export_folder + 'reworkedSegments.csv', index=False)\n",
    "# Load a copy of the reworked segments dataframe to avoid reprocessing each time\n",
    "reworkedSegments = pd.read_csv(export_folder + 'reworkedSegments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning the lines and variants\n",
    "The initial dataset provides information about variants that are not part of the normal itinerary of the line (e.g. some metro 1 go to Delta at the end of their shift to go to the storage facility). As we want to use linear measures for spacial progress along a line, multiple \"bastard\" alternatives are not suitable to perform a successful analysis. We eliminate them from the scope of the analysis.\n",
    "\n",
    "Required steps:\n",
    "* Remove duplicate stops on the same line variant\n",
    "* Reindex the succession variable\n",
    "* Obtain the previous stop if existing (set the startup place otherwise)\n",
    "* Obtain the distance between the two stops as determined in the previously cleaned segments dataframe\n",
    "* Calculate the cumulative sum of the stop relative to the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates stops on the same line variant\n",
    "moddedLineStops = linestops_df.drop_duplicates(['lineId', 'Variante', 'descr_fr'])\n",
    "\n",
    "# Used to store all the line variants dataframes\n",
    "tmpModded = []\n",
    "\n",
    "# Create the list of lines\n",
    "listOfLines = moddedLineStops.lineId.drop_duplicates().to_list()\n",
    "\n",
    "for currentWorkingLine in listOfLines:\n",
    "    # Get each variant of the line (normally 1/2 but you are never too cautious)\n",
    "    currentLineVariants = moddedLineStops[moddedLineStops.lineId == currentWorkingLine].Variante.drop_duplicates().to_list()\n",
    "\n",
    "    # Perform reindexing and append to tmpModded\n",
    "    for currentWorkingVariant in currentLineVariants:\n",
    "        myVariant = moddedLineStops[(moddedLineStops.lineId == currentWorkingLine) & (moddedLineStops.Variante == currentWorkingVariant)].sort_values(by='succession')\n",
    "        variantLength = len(myVariant)\n",
    "        # Change the order ID\n",
    "        myVariant['succession'] = range(1, variantLength + 1)\n",
    "\n",
    "        tmpModded.append(myVariant)\n",
    "\n",
    "moddedLineStops = pd.concat(tmpModded).reset_index(drop=True)\n",
    "\n",
    "# Function used to obtain the position of the previous stop on the line\n",
    "def previousStopNumber(row):\n",
    "    if (row['succession'] == 1):\n",
    "        return row['succession']\n",
    "    else:\n",
    "        return row['succession'] - 1\n",
    "\n",
    "# Obtain the position of the previous stop and their name\n",
    "moddedLineStops['previous'] = moddedLineStops.apply(lambda row: previousStopNumber(row), axis=1)\n",
    "# Merge to obtain the name on the line\n",
    "moddedLineStops = moddedLineStops.merge(moddedLineStops[['lineId', 'Variante', 'succession', 'descr_fr']], left_on=['lineId', 'Variante', 'previous'], right_on=['lineId', 'Variante', 'succession'], how='left')\n",
    "moddedLineStops.drop(columns=['previous'], inplace=True)\n",
    "moddedLineStops.rename(columns={'succession_x' : 'currentPosition', 'succession_y' : 'previousPosition', 'descr_fr_x' : 'currentName', 'descr_fr_y' : 'previousName'}, inplace=True)\n",
    "\n",
    "# Merge with the distance between the two stops\n",
    "moddedLineStops = moddedLineStops.merge(reworkedSegments[['lineId', 'start_stop_name', 'end_stop_name', 'distance_m']], left_on=['lineId', 'previousName', 'currentName'], right_on=['lineId', 'start_stop_name', 'end_stop_name'], how='left')\n",
    "moddedLineStops.drop(columns=['start_stop_name', 'end_stop_name'], inplace=True)\n",
    "moddedLineStops['distance_m'] = moddedLineStops['distance_m'].fillna(value=0)\n",
    "\n",
    "# Function used to obtain the position of the next stop on the line\n",
    "def nextStopNumber(row):\n",
    "    # Define the variant max\n",
    "    maxOfLineVariant = moddedLineStops[(moddedLineStops.lineId == row['lineId']) & (moddedLineStops.Variante == row['Variante'])]['currentPosition'].max()\n",
    "    # Attribute the proper number\n",
    "    \n",
    "    if (row['currentPosition'] == maxOfLineVariant):\n",
    "        return row['currentPosition']\n",
    "    else:\n",
    "        return row['currentPosition'] + 1\n",
    "\n",
    "# Obtain the position of the next stop and their name\n",
    "moddedLineStops['next'] = moddedLineStops.apply(lambda row: nextStopNumber(row), axis=1)\n",
    "\n",
    "# Merge to obtain the name on the line\n",
    "moddedLineStops = moddedLineStops.merge(moddedLineStops[['lineId', 'Variante', 'currentPosition', 'currentName']], left_on=['lineId', 'Variante', 'next'], right_on=['lineId', 'Variante', 'currentPosition'], how='left')\n",
    "moddedLineStops.drop(columns=['next'], inplace=True)\n",
    "moddedLineStops.rename(columns={'currentPosition_x' : 'currentPosition', 'currentPosition_y' : 'nextPosition', 'currentName_x' : 'currentName', 'currentName_y' : 'nextName'}, inplace=True)\n",
    "\n",
    "#\n",
    "# Calculate the cumulated distance\n",
    "#\n",
    "tmpLineStops = []\n",
    "\n",
    "# Perform on each line\n",
    "for currentWorkingLine in listOfLines:\n",
    "    # Get each variant of the line\n",
    "    currentLineVariants = moddedLineStops[moddedLineStops.lineId == currentWorkingLine].Variante.drop_duplicates().to_list()\n",
    "    \n",
    "    # Perform reindexing and append to tmpModdedSegments\n",
    "    for currentWorkingVariant in currentLineVariants:\n",
    "        currentVariant = moddedLineStops[(moddedLineStops.lineId == currentWorkingLine) & (moddedLineStops.Variante == currentWorkingVariant)]\n",
    "        currentVariant = currentVariant.sort_values(by='currentPosition').reset_index(drop=True)\n",
    "        currentVariant['cumulatedDistance'] = currentVariant['distance_m'].cumsum()\n",
    "\n",
    "        tmpLineStops.append(currentVariant)\n",
    "\n",
    "# Merge everything under a single df\n",
    "moddedLineStops = pd.concat(tmpLineStops).reset_index(drop=True)\n",
    "moddedLineStops.drop(columns=['previousPosition', 'previousName'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the modded linestops dataframe\n",
    "#moddedLineStops.to_csv(export_folder + 'moddedLineStops.csv', index=False)\n",
    "# Load a copy of the modded linestops dataframe to avoid reprocessing each time\n",
    "moddedLineStops = pd.read_csv(export_folder + 'moddedLineStops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LineStopsPosition = moddedLineStops[['lineId', 'currentName', 'currentPosition', 'Variante']].drop_duplicates(['lineId', 'currentName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the modded linestops dataframe\n",
    "#LineStopsPosition.to_csv(export_folder + 'LineStopsPosition.csv', index=False)\n",
    "# Load a copy of the modded linestops dataframe to avoid reprocessing each time\n",
    "LineStopsPosition = pd.read_csv(export_folder + 'LineStopsPosition.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reworking positions\n",
    "This operations aims at:\n",
    "* Getting the stop names to replace the ID (and remove unknown stations) ;\n",
    "* Only keep stops and terminus that actually belong to the line ;\n",
    "* Define the direction of the data point ;\n",
    "* Obtain the stop position on the variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the generic label belonging to the stop ID\n",
    "reworkedPositions = positions_df.merge(IDStops, left_on=['directionId'], right_on=['stop_id'], how='left')\n",
    "reworkedPositions.rename(columns={'stop_name' : 'directionName'}, inplace=True)\n",
    "reworkedPositions = reworkedPositions.merge(IDStops, left_on=['pointId'], right_on=['stop_id'], how='left')\n",
    "reworkedPositions.rename(columns={'stop_name' : 'pointName'}, inplace=True)\n",
    "reworkedPositions.drop(columns=['stop_id_x', 'stop_id_y', 'directionId', 'pointId'], inplace=True)\n",
    "\n",
    "# Remove lines with unknown stations\n",
    "reworkedPositions = reworkedPositions.dropna()\n",
    "\n",
    "# Only keep stops that belong to the said line\n",
    "reworkedPositions = reworkedPositions.merge(LineStopsPosition[['lineId', 'currentName']], left_on=['lineId', 'pointName'], right_on=['lineId', 'currentName'], how='left')\n",
    "reworkedPositions = reworkedPositions.dropna(subset=['currentName'])\n",
    "reworkedPositions.drop(columns=['currentName'], inplace=True)\n",
    "\n",
    "# Only keep terminus that belong to the said line\n",
    "reworkedPositions = reworkedPositions.merge(LineStopsPosition[['lineId', 'currentName']], left_on=['lineId', 'directionName'], right_on=['lineId', 'currentName'], how='left')\n",
    "reworkedPositions = reworkedPositions.dropna(subset=['currentName'])\n",
    "reworkedPositions.drop(columns=['currentName'], inplace=True)\n",
    "\n",
    "# Determine the direction of the data points\n",
    "reworkedPositions = reworkedPositions.merge(LineStopsPosition[['lineId', 'currentName', 'currentPosition']], left_on=['lineId', 'directionName'], right_on=['lineId', 'currentName'], how='left')\n",
    "reworkedPositions.rename(columns={'currentPosition' : 'directionPosition'}, inplace=True)\n",
    "reworkedPositions = reworkedPositions.merge(LineStopsPosition[['lineId', 'currentName', 'currentPosition', 'Variante']], left_on=['lineId', 'pointName'], right_on=['lineId', 'currentName'], how='left')\n",
    "reworkedPositions.rename(columns={'currentPosition' : 'pointPosition'}, inplace=True)\n",
    "reworkedPositions.drop(columns=['currentName_x', 'currentName_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to reassign the proper variant according to the point and direction\n",
    "def correctVariants(row):\n",
    "    if ((row['Variante'] == 1) & (row['pointPosition'] <= row['directionPosition'])):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# Reassign the proper variant according to the position of the point and direction\n",
    "reworkedPositions['Variante'] = reworkedPositions.apply(lambda row: correctVariants(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove previous values obtained for directionPosition and pointPosition\n",
    "reworkedPositions.drop(columns=['directionPosition', 'pointPosition'], inplace=True)\n",
    "\n",
    "# Obtain the true position of the point on the line\n",
    "reworkedPositions = reworkedPositions.merge(moddedLineStops[['lineId', 'Variante', 'currentName', 'currentPosition', 'mode', 'nextName', 'cumulatedDistance']], left_on=['lineId', 'Variante', 'pointName'], right_on=['lineId', 'Variante', 'currentName'], how='left')\n",
    "reworkedPositions.rename(columns={'currentPosition' : 'pointPosition'}, inplace=True)\n",
    "reworkedPositions = reworkedPositions.merge(moddedLineStops[['lineId', 'Variante', 'currentName', 'currentPosition']], left_on=['lineId', 'Variante', 'directionName'], right_on=['lineId', 'Variante', 'currentName'], how='left')\n",
    "reworkedPositions.rename(columns={'currentPosition' : 'directionPosition'}, inplace=True)\n",
    "reworkedPositions.drop(columns=['currentName_x', 'currentName_y'], inplace=True)\n",
    "\n",
    "# Remove problematic records and recast\n",
    "reworkedPositions.dropna(subset=['directionPosition', 'pointPosition'], inplace=True)\n",
    "reworkedPositions = reworkedPositions.astype({'directionPosition': 'int16', 'pointPosition': 'int16', 'Variante' : 'int16'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep a copy of the reworked positions dataframe\n",
    "#reworkedPositions.to_csv(export_folder + 'reworkedPositions.csv', index=False)\n",
    "# Load a copy of the reworked positions dataframe to avoid reprocessing each time\n",
    "reworkedPositions = pd.read_csv(export_folder + 'reworkedPositions.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ec7bd7830e1389ad0e956034e4c95e16eb9cab103064e78d4babc7287c4ec45a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
