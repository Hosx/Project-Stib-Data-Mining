{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook pour calculer les Excess Waiting Time.\n",
    "Tout d'abord on a besoin des packages pour Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtfs_functions as gtfs\n",
    "import matplotlib\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# cluster visualizer\n",
    "#%matplotlib inline\n",
    "#from yellowbrick.cluster import KElbowVisualizer \n",
    "\n",
    "# sklearn kmeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "# pyclustering kmeans\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.utils.metric import distance_metric\n",
    "from pyclustering.cluster.center_initializer import random_center_initializer\n",
    "from pyclustering.cluster.encoder import type_encoding\n",
    "from pyclustering.cluster.encoder import cluster_encoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest = min(np.array([1,2,3,4,5,6]),key=lambda x: abs(x-4.5))\n",
    "closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the schedule\n",
    "\n",
    "path_gtfs ='C:/Users/Maison/Documents/INFO-H423/Projet Data Mining/GTFS3sep/gtfs3sept.zip'\n",
    "\n",
    "routes, stops, stop_times, trips, shapes = gtfs.import_gtfs(path_gtfs,busiest_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the calendar by hand \n",
    "\n",
    "calendardf = pd.read_table('calendar.txt',sep=',')          #export the calendar file into data frame\n",
    "calendarDatesdf = pd.read_table('calendar_dates.txt',sep=',')  #also export the exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FromDayToService(date):\n",
    "    '''Determine all the service_id concerned by a date, given in the format date=('20210907','tuesday')\n",
    "        it first take a look at every regular service_id then examine the exceptions. \n",
    "        Returns a list of service_id of type string'''\n",
    "\n",
    "    ListServiceId=[]\n",
    "    for i in range(len(calendardf)):\n",
    "        startdate,endate=calendardf.iloc[i,[8,9]]\n",
    "        if int(date[0]) in range(int(startdate),int(endate)+1):\n",
    "            if calendardf.loc[i,date[1]]==1:\n",
    "                #It appends every service_id which contains the date, and for which there is a '1'\n",
    "                # under right day in the week\n",
    "                ListServiceId.append(str(calendardf.iloc[i,0]))     \n",
    "\n",
    "    #Now we have to take a look a the exceptions\n",
    "    #We selections all the exceptions in calendarDatesdf that concerns the date in the input\n",
    "    ModifServiceId= calendarDatesdf[calendarDatesdf['date']==int(date[0])][['service_id','exception_type']]\n",
    "    #print('Number of service_id involved in modifications: '+ str(len(ModifServiceId)))\n",
    "    #for every modif we check the kind of exception\n",
    "    for modif in ModifServiceId.iterrows():  \n",
    "        service = str(modif[1]['service_id'])\n",
    "        exception = modif[1]['exception_type']\n",
    "        if exception == 1:\n",
    "            #if the exception is 1, it means that we should change to a 1 the cell related to the date in\n",
    "            # input, in the row equal to service in calendar\n",
    "            ListServiceId.append(service)\n",
    "            #print('ServiceId: '+str(service)+' correclty added' )\n",
    "        elif (exception == 2) & (service in ListServiceId):\n",
    "            #if the exception is 2, it means that we should change to a 0 the cell related to the date in\n",
    "            # input, in the row equal to service in calendar\n",
    "            #Since this service_id must have been selected in the first loop (in Calendar), we need to remove it\n",
    "            ListServiceId.remove(service)\n",
    "            #print('ServiceId: '+str(service)+' correclty removed' )\n",
    "        elif (exception == 2) & (service not in ListServiceId):\n",
    "            #if the exception is 2 but we haven't found the service id in the first loop, this is weird\n",
    "            #In principle this should not happend, but we're never too carefull\n",
    "            print('Warning : exception 2 but no service_id = ' +service+ ' found in calendar')\n",
    "    return (ListServiceId)\n",
    "\n",
    "def FromLineIdtoRouteId(LineId):\n",
    "    \n",
    "    '''Takes a lineid in argument a returns the correspondent routeid, since stop_times only \n",
    "        contains route_id'''\n",
    "\n",
    "    routeId = routes[routes['route_short_name']==LineId]['route_id'].iloc[0]\n",
    "    return routeId\n",
    "\n",
    "def ScheduledTime(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,routeid,stopId) with date in the format date=('20210907','tuesday')\n",
    "        and returns the schedule for that triplet. The schedule is composed as follows: if we are in a period of\n",
    "        punctuality then returns the (arrivaltime,true), and if we are in regularity, \n",
    "        returns (TimeOfWaitFromPreviousVehicle,False), all in one list '''\n",
    "\n",
    "    ListOfService = pd.Series(FromDayToService(date))  #List of service_id tha apply for that day\n",
    "    #RouteId = FromLineIdtoRouteId(lineId)               #We need the routeid to seek in the GTFS\n",
    "    #We select the relevant rows in GTFS stop_times\n",
    "    Scheduledf = stop_times[(stop_times['stop_id']==stopId)&(stop_times['route_id']==routeid)&(stop_times['service_id'].isin(ListOfService))].sort_values('arrival_time')\n",
    "    ArrivalTime = Scheduledf['arrival_time'].values\n",
    "    #print('Number of service_id involved: '+ str(len(ListOfService)))\n",
    "    #We compute every wainting time to determine punctuality of regularity (< or > 720 s)\n",
    "    #Schedule = list(ArrivalTime[1:]-ArrivalTime[:-1])\n",
    "    IntervalTime = list(ArrivalTime[1:]-ArrivalTime[:-1])\n",
    "    #Schedule.insert(0,ArrivalTime[0])\n",
    "    #True if punctuality, False if regularity\n",
    "    Punctuality = np.array(IntervalTime)>720 \n",
    "    #Ultimately, if we are a punctuality, we want the arrival time and if we are in regularity, we want the \n",
    "    #time bewteen two vehicles\n",
    "    for i,punctuality in enumerate(Punctuality):\n",
    "        if punctuality:\n",
    "            if (0<i<(len(Punctuality)-1)):\n",
    "                if ~(Punctuality[i-1]) & ~(Punctuality[i+1]):\n",
    "                    Punctuality[i]=False\n",
    "            else:\n",
    "                IntervalTime[i]=ArrivalTime[i]\n",
    " \n",
    "    #Schedule = list(zip(Schedule,Punctuality))\n",
    "    #The format is a list of tuples\n",
    "    if len(IntervalTime)!=len(ArrivalTime[:-1]):\n",
    "        print('Attention: la longueur de Schedule et ArrivalTime ne match pas dans ScheduledTime ')\n",
    "    return IntervalTime,Punctuality,ArrivalTime[:-1]\n",
    "\n",
    "def RouteIdToLineId(routeId):\n",
    "\n",
    "    '''Takes a routeid in argument a returns the correspondent lineid'''\n",
    "\n",
    "    lineId = routes[routes['route_id']==routeId]['route_short_name'].iloc[0]\n",
    "    return lineId\n",
    "\n",
    "def TroncatedScheduleRegularity(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,routeid,stopId) in the format date=('20210907','tuesday') and returns the IntervalTime \n",
    "        and ArrivalTime cleared from the ponctuality point'''\n",
    "    ScheduleNonCleared = ScheduledTime(date,routeid,stopId)\n",
    "    TroncatedInterval = [intervaltime for i,intervaltime in enumerate(ScheduleNonCleared[0]) if not(ScheduleNonCleared[1][i])]\n",
    "    TroncatedArrival = [arrivaltime for i,arrivaltime in enumerate(ScheduleNonCleared[2]) if not(ScheduleNonCleared[1][i])]\n",
    "    if len(TroncatedInterval)!= len(TroncatedArrival):\n",
    "        print('Attention: la longueur de TroncatedInterval et TroncatedArrival ne match pas dans TroncatedScheduleRegularity ')\n",
    "    return TroncatedInterval,TroncatedArrival"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow is the cell that compute the middle stop from a line in a specific direction, not really relevant now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopTimesGroupTrip = stop_times.groupby('trip_id')[['stop_sequence']].mean().round()\n",
    "StopTimesGroupTrip['stop_sequence']=StopTimesGroupTrip['stop_sequence'].astype(int)\n",
    "\n",
    "StopTimesOnlyMeanSeq = pd.merge(stop_times, StopTimesGroupTrip, how='right', on= ['trip_id','stop_sequence'])\n",
    "StopTimesOnlyMeanSeq = StopTimesOnlyMeanSeq[['route_id','stop_sequence','stop_id','direction_id']]\n",
    "DicOfMiddleStop={}\n",
    "\n",
    "for route in StopTimesOnlyMeanSeq['route_id'].unique():\n",
    "    StopTimeMeanSeqRoute = StopTimesOnlyMeanSeq[StopTimesOnlyMeanSeq['route_id']==route]\n",
    "    directionIds = StopTimeMeanSeqRoute['direction_id'].unique()\n",
    "    for direction in directionIds:\n",
    "        #Ici je prends la première valeure que je trouve qui a la bonne route et direction\n",
    "        # car il peut y avoir plusieurs candidat Middle stop pour chaque (ligne,direction)\n",
    "        # ici je prend le premier parce que j'en ai très exactement rien à fouttre\n",
    "        stop = StopTimeMeanSeqRoute[StopTimeMeanSeqRoute['direction_id']==direction]['stop_id'].values[0]\n",
    "        value = str(route)+':'+str(direction)\n",
    "        if DicOfMiddleStop.get(stop) is None:\n",
    "            DicOfMiddleStop[stop]=value\n",
    "\n",
    "\n",
    "#Format du dico : 'middle_stop_id': 'routeid:direction'    Ex: '5510': '41:0'\n",
    "\n",
    "#Ici c'est juste pour lui dire quelle date prendre en exemple si on dit 'weekday', 'satuday', etc...\n",
    "DicOfWeek = {'weekday':('20210915','wednesday'),'saturday':('20210918','saturday'),'sunday':('20210919','sunday')}\n",
    "\n",
    "#liste des middle stop\n",
    "ListOfMiddleStop= list(DicOfMiddleStop.keys())\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in DicOfMiddleStop.items():\n",
    "        if val == value:\n",
    "            return key\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need the algorithm to cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dictionary for distance measures\n",
    "distance_measures = {'euclidean': 0, 'squared euclidean': 1, 'manhattan': 2, 'chebyshev': 3, \n",
    "                    'canberra': 5, 'chi-square': 6}\n",
    "\n",
    "# function defined to compute purity score using pyclustering for various distance measures\n",
    "def Clustering(dist_measure,nclust,data):\n",
    "    initial_centers = random_center_initializer(data.values, nclust, random_state=5).initialize()\n",
    "    # instance created for respective distance metric\n",
    "    instanceKm = kmeans(data.values, initial_centers=initial_centers, metric=distance_metric(dist_measure))\n",
    "    # perform cluster analysis\n",
    "    instanceKm.process()\n",
    "    # cluster analysis results - clusters and centers\n",
    "    pyClusters = instanceKm.get_clusters()\n",
    "    pyCenters = instanceKm.get_centers()\n",
    "    # enumerate encoding type to index labeling to get labels\n",
    "    pyEncoding = instanceKm.get_cluster_encoding()\n",
    "    pyEncoder = cluster_encoder(pyEncoding, pyClusters, data.values)\n",
    "    pyLabels = pyEncoder.set_encoding(0).get_clusters()\n",
    "    # function purity score is defined in previous section\n",
    "\n",
    "    return(pyClusters,pyCenters)\n",
    "    #return purity_score(IntervalTimeBetweenVehicle['TimeInterval'].values, pyLabels)\n",
    "\n",
    "# print results\n",
    "#for measure, value in distance_measures.items():\n",
    "    #print(f\"The purity score for {measure} distance is {round(pyPurity(value)*100, 2)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tout est en place pour commencer un exemple qui portera sur le mercredi 15/09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DateExample = ('20210915','wednesday')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'abord on va venir mettre toute la data qui concerne cette date dans un CSV, par arrêt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListOfStopId  = list(stop_times['stop_id'].unique())\n",
    "DicOfStopInRoute = {}\n",
    "for route in routes['route_id']:\n",
    "    ListOfStop = [stop for stop in stop_times[stop_times['route_id']==route]['stop_id'].unique()]\n",
    "    DicOfStopInRoute[route]=ListOfStop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScheduledTimeCSV(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,lineId,stopId) with date in the format date=('20210907','tuesday')\n",
    "        and returns the schedule for that triplet. THE DIFFERENCE WITH ScheduledTime IS THAT WE DONT\n",
    "        NEED THE PUNCTUALITY'''\n",
    "\n",
    "    ListOfService = pd.Series(FromDayToService(date))              #We need the routeid to seek in the GTFS\n",
    "    #We select the relevant rows in GTFS stop_times\n",
    "    Scheduledf = stop_times[(stop_times['stop_id']==stopId)&(stop_times['route_id']==routeid)&(stop_times['service_id'].isin(ListOfService))].sort_values('arrival_time')\n",
    "    directionId = Scheduledf['direction_id'].unique()\n",
    "    ArrivalTime = Scheduledf['arrival_time'].values\n",
    "    \n",
    "\n",
    "    return ArrivalTime,directionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime ~ 30min\n",
    "\n",
    "#DO NOT RUN THE CELL, OTHERWISE IT WILL WRITE OVER THE EXISTING FILE AND YOU'LL HAVE TO WAIT 30min\n",
    "\n",
    "headerSchedule = ['route_id','stop_id','ArrivalTime']\n",
    "\n",
    "with open('Schedule20210915.csv', 'w', encoding='UTF8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(headerSchedule)\n",
    "    k=0\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            ArrivalTime,directionId = ScheduledTimeCSV(DateExample,route,stop)\n",
    "            for arrival in ArrivalTime:\n",
    "                row = [route,stop,arrival]\n",
    "                writer.writerow(row)\n",
    "            \n",
    "        k+=1\n",
    "        if k%2==0:\n",
    "            break\n",
    "            print(str(k*l)+' lignes encodées')\n",
    "            k=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'exemple regardons au format d'une ligne du CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 arrêts encodés\n",
      "100.0 arrêts encodés\n",
      "200.0 arrêts encodés\n",
      "300.0 arrêts encodés\n",
      "400.0 arrêts encodés\n",
      "500.0 arrêts encodés\n",
      "600.0 arrêts encodés\n",
      "700.0 arrêts encodés\n",
      "800.0 arrêts encodés\n",
      "900.0 arrêts encodés\n",
      "1000.0 arrêts encodés\n",
      "1100.0 arrêts encodés\n",
      "1200.0 arrêts encodés\n",
      "1300.0 arrêts encodés\n",
      "1400.0 arrêts encodés\n",
      "1500.0 arrêts encodés\n",
      "1600.0 arrêts encodés\n",
      "1700.0 arrêts encodés\n",
      "1800.0 arrêts encodés\n",
      "1900.0 arrêts encodés\n",
      "2000.0 arrêts encodés\n",
      "2100.0 arrêts encodés\n",
      "2200.0 arrêts encodés\n",
      "2300.0 arrêts encodés\n",
      "2400.0 arrêts encodés\n",
      "2500.0 arrêts encodés\n",
      "2600.0 arrêts encodés\n",
      "2700.0 arrêts encodés\n",
      "2800.0 arrêts encodés\n",
      "2900.0 arrêts encodés\n",
      "3000.0 arrêts encodés\n",
      "3100.0 arrêts encodés\n",
      "3200.0 arrêts encodés\n",
      "3300.0 arrêts encodés\n",
      "3400.0 arrêts encodés\n",
      "3500.0 arrêts encodés\n",
      "3600.0 arrêts encodés\n",
      "3700.0 arrêts encodés\n",
      "3800.0 arrêts encodés\n",
      "3900.0 arrêts encodés\n",
      "4000.0 arrêts encodés\n",
      "4100.0 arrêts encodés\n",
      "4200.0 arrêts encodés\n",
      "4300.0 arrêts encodés\n",
      "4400.0 arrêts encodés\n",
      "4500.0 arrêts encodés\n",
      "4600.0 arrêts encodés\n",
      "4700.0 arrêts encodés\n",
      "4800.0 arrêts encodés\n",
      "4900.0 arrêts encodés\n"
     ]
    }
   ],
   "source": [
    "ReadSchedule = csv.reader(open('Schedule20210915.csv', 'r'),delimiter=',')\n",
    "\n",
    "headerSchedule = ['route_id','direction_id','stop_id','ArrivalTime']\n",
    "\n",
    "with open('SchedulePunc20210915.csv', 'w', encoding='UTF8',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    for i,row in enumerate(ReadSchedule):\n",
    "        \n",
    "        if len(row)>4:\n",
    "            ArrivalTime = (np.array(row[3:])).astype(np.float64)\n",
    "            IntervalTime = ArrivalTime[1:]-ArrivalTime[:-1]\n",
    "            Punctuality = IntervalTime>720\n",
    "            ArrivalTimePunct = [arrival for k,arrival in enumerate(ArrivalTime[:-1]) if Punctuality[k]]\n",
    "            for arrivalnew in ArrivalTimePunct:\n",
    "                RowToWrite=[row[0],row[2],arrivalnew]\n",
    "                writer.writerow(RowToWrite)\n",
    "        if i%200==0:\n",
    "            print(str(i/2)+' arrêts encodés')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 arrêts encodés\n",
      "100 arrêts encodés\n",
      "200 arrêts encodés\n",
      "300 arrêts encodés\n",
      "400 arrêts encodés\n",
      "500 arrêts encodés\n",
      "600 arrêts encodés\n",
      "700 arrêts encodés\n",
      "800 arrêts encodés\n",
      "900 arrêts encodés\n",
      "1000 arrêts encodés\n",
      "1100 arrêts encodés\n",
      "1200 arrêts encodés\n",
      "1300 arrêts encodés\n",
      "1400 arrêts encodés\n",
      "1500 arrêts encodés\n",
      "1600 arrêts encodés\n",
      "1700 arrêts encodés\n",
      "1800 arrêts encodés\n",
      "1900 arrêts encodés\n",
      "2000 arrêts encodés\n",
      "2100 arrêts encodés\n",
      "2200 arrêts encodés\n",
      "2300 arrêts encodés\n",
      "2400 arrêts encodés\n",
      "2500 arrêts encodés\n",
      "2600 arrêts encodés\n",
      "2700 arrêts encodés\n",
      "2800 arrêts encodés\n",
      "2900 arrêts encodés\n",
      "3000 arrêts encodés\n",
      "3100 arrêts encodés\n",
      "3200 arrêts encodés\n",
      "3300 arrêts encodés\n",
      "3400 arrêts encodés\n",
      "3500 arrêts encodés\n",
      "3600 arrêts encodés\n",
      "3700 arrêts encodés\n"
     ]
    }
   ],
   "source": [
    "ReadJSON = csv.reader(open('stop_times_line_version4.csv','r'),delimiter=',')\n",
    "header = ['route_id','stop_id','ArrivalTime']\n",
    "\n",
    "with open('stop_time_line_cleared2_forDF.csv', 'w', encoding='UTF8',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    for i,rowJSON in enumerate(ReadJSON):\n",
    "        if len(rowJSON)>2:\n",
    "            route = FromLineIdtoRouteId(rowJSON[0])\n",
    "            stop = rowJSON[1]\n",
    "            ArrivalTime = np.array(rowJSON[2].split(',')).astype(np.float64)\n",
    "            #IntervalTime = ArrivalTime[1:]-ArrivalTime[:-1]\n",
    "            for arrivalJSON in ArrivalTime:\n",
    "                RowToWrite=[route,stop,arrivalJSON]\n",
    "                writer.writerow(RowToWrite)\n",
    "        if i%100==0:\n",
    "            print(str(i)+' arrêts encodés')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8011, 8012, 8021, ..., 5964, 9649, 9686], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SchedulePuncdf = pd.read_csv('SchedulePunc20210915.csv')\n",
    "JSONArrival = pd.read_csv('stop_time_line_cleared2_forDF.csv')\n",
    "JSONArrival[(JSONArrival['stop_id']=='2')&(JSONArrival['route_id']==8161)]\n",
    "JSONArrival['stop_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_code</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_desc</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>stop_url</th>\n",
       "      <th>location_type</th>\n",
       "      <th>parent_station</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>5770F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VAN PRAET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (4.37360 50.88127)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stop_id stop_code  stop_name stop_desc zone_id stop_url  location_type  \\\n",
       "2119   5770F       NaN  VAN PRAET       NaN     NaN      NaN              0   \n",
       "\n",
       "     parent_station                  geometry  \n",
       "2119            NaN  POINT (4.37360 50.88127)  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SchedulePuncdf[SchedulePuncdf['stop_id']=='5770F']\n",
    "stops[stops['stop_id']=='5770F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 226 fields in line 573, saw 281\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14912\\2562761023.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mScheduledf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Schedule20210915.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mSchedulePuncdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'SchedulePunc20210915.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mJSONArrival\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stop_time_line_cleared2_forDF.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mSchedulePuncdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSchedulePuncdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'route_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'65'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSchedulePuncdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stop_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'2595'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1253\u001b[1;33m                 \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1254\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 225\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    226\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Maison\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 226 fields in line 573, saw 281\n"
     ]
    }
   ],
   "source": [
    "SchedulePuncdf = pd.read_csv('SchedulePunc20210915.csv')\n",
    "JSONArrival = pd.read_csv('stop_time_line_cleared2_forDF.csv')\n",
    "\n",
    "SchedulePuncdf[(SchedulePuncdf['route_id']=='65')&(SchedulePuncdf['stop_id']=='2595')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 arrêts encodés\n",
      "20 arrêts encodés\n",
      "30 arrêts encodés\n",
      "40 arrêts encodés\n",
      "50 arrêts encodés\n",
      "60 arrêts encodés\n",
      "70 arrêts encodés\n",
      "80 arrêts encodés\n",
      "90 arrêts encodés\n"
     ]
    }
   ],
   "source": [
    "#Fonction Vic ponctualité\n",
    "\n",
    "SchedulePuncdf = pd.read_csv('SchedulePunc20210915.csv')\n",
    "JSONArrival = pd.read_csv('stop_time_line_cleared2_forDF.csv')\n",
    "\n",
    "#ReadSchedule = csv.reader(open('SchedulePunc20210915.csv', 'r'),delimiter=',')\n",
    "#ReadJSON = csv.reader(open('stop_times_line_cleared2.csv','r'),delimiter=',')\n",
    "\n",
    "\n",
    "header = ['route_id','stop_id','ArrivalTime','Difference']\n",
    "\n",
    "with open('PunctualityExplore.csv', 'w', encoding='UTF8',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    l=0\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            if stop.isnumeric():\n",
    "                SchedulePuncdfForStop = SchedulePuncdf[(SchedulePuncdf['route_id']==int(route)) & (SchedulePuncdf['stop_id']==str(stop))]\n",
    "                if len(SchedulePuncdfForStop)>0:\n",
    "                    JSONArrivaldfForStop = JSONArrival[(JSONArrival['stop_id']==int(stop))&(JSONArrival['route_id']==int(route))]\n",
    "                    if len(JSONArrivaldfForStop)>0:\n",
    "                        ArrivalTime = JSONArrivaldfForStop['ArrivalTime'].values\n",
    "                        for arrival in ArrivalTime:\n",
    "                                closest = min(SchedulePuncdfForStop['ArrivalTime'].values,key=lambda x: abs(x-arrival))\n",
    "                                difference = arrival-closest\n",
    "                                RowToWrite=[route,stop,arrival,difference]\n",
    "                                writer.writerow(RowToWrite)\n",
    "                            \n",
    "        l+=1\n",
    "        if l%10==0:\n",
    "            print(str(l)+' arrêts encodés')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>ArrivalTime</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>18005.317</td>\n",
       "      <td>-55269.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>18222.923</td>\n",
       "      <td>-55052.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>18316.213</td>\n",
       "      <td>-54958.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>18408.887</td>\n",
       "      <td>-54866.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>18692.339</td>\n",
       "      <td>-54582.661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   route_id  stop_id  ArrivalTime  Difference\n",
       "0         2     8161    18005.317  -55269.683\n",
       "1         2     8161    18222.923  -55052.077\n",
       "2         2     8161    18316.213  -54958.787\n",
       "3         2     8161    18408.887  -54866.113\n",
       "4         2     8161    18692.339  -54582.661"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "MeasurePunc = pd.read_csv('PunctualityExplore.csv')\n",
    "MeasurePunc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'differenceList' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2632\\3059038088.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mTemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mDifferenceScheduleJSON\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'6423F'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'10'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mTemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2632\\4228707677.py\u001b[0m in \u001b[0;36mDifferenceScheduleJSON\u001b[1;34m(stop, route, ArrivalTimeScheduleArray)\u001b[0m\n\u001b[0;32m     16\u001b[0m                 \u001b[0mdifference\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrival\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mclosest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mdifferenceList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdifferenceList\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'differenceList' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if (RowReal[0]==line) & (RowReal[1]==stop):\n",
    "                    ArrivalTime = np.array(RowReal[3].split(',')).astype(np.float64)\n",
    "                    differenceList = []\n",
    "                    for arrival in ArrivalTime:\n",
    "                        closest = min(SchedulePuncdfForStop['ArrivalTime'].values,key=lambda x: abs(x-arrival))\n",
    "                        difference = arrival-closest\n",
    "                        RowToWrite = []\n",
    "\n",
    "\n",
    "def DifferenceScheduleJSON(stop,route,ArrivalTimeScheduleArray):\n",
    "    \n",
    "    line = RouteIdToLineId(route)\n",
    "    for i,RowReal in enumerate(ReadJSON):\n",
    "        if (RowReal[0]==line) & (RowReal[1]==stop):\n",
    "            ArrivalTime = np.array(RowReal[3].split(',')).astype(np.float64)\n",
    "            differenceList = []\n",
    "            print('flag2')\n",
    "            for arrival in ArrivalTime:\n",
    "                closest = min(ArrivalTimeScheduleArray,key=lambda x: abs(x-arrival))\n",
    "                difference = arrival-closest\n",
    "                differenceList.append(difference)\n",
    "    return(differenceList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2', '[1 0]', '8161', '19800.0', '19939.0', '20433.0', '20700.0', '21053.0', '21764.0', '22293.0', '22533.0', '22893.0', '23106.0', '23496.0', '23742.0', '24126.0', '24401.0', '24746.0', '25007.0', '25366.0', '25627.0', '25986.0', '26247.0', '26606.0', '26867.0', '27226.0', '27487.0', '27846.0', '28107.0', '28466.0', '28727.0', '29086.0', '29347.0', '29706.0', '29967.0', '30326.0', '30587.0', '30946.0', '31207.0', '31566.0', '31827.0', '32186.0', '32447.0', '32806.0', '33067.0', '33426.0', '33687.0', '34046.0', '34307.0', '34666.0', '34927.0', '35286.0', '35547.0', '35906.0', '36167.0', '36526.0', '36787.0', '37215.0', '37407.0', '37846.0', '38021.0', '38628.0', '39142.0', '39248.0', '39592.0', '39868.0', '40492.0', '40667.0', '40942.0', '41117.0', '41392.0', '41582.0', '41842.0', '42017.0', '42292.0', '42467.0', '42742.0', '42917.0', '43192.0', '43367.0', '43642.0', '43817.0', '44092.0', '44267.0', '44542.0', '44717.0', '44992.0', '45167.0', '45442.0', '45617.0', '45892.0', '46067.0', '46342.0', '46517.0', '46792.0', '46967.0', '47242.0', '47417.0', '47692.0', '47867.0', '48142.0', '48317.0', '48592.0', '48767.0', '49042.0', '49217.0', '49492.0', '49667.0', '49942.0', '50117.0', '50392.0', '50567.0', '50842.0', '51017.0', '51292.0', '51467.0', '51742.0', '51917.0', '52192.0', '52367.0', '52642.0', '52817.0', '53057.0', '53267.0', '53507.0', '53567.0', '53848.0', '54167.0', '54468.0', '54617.0', '55088.0', '55367.0', '55698.0', '55968.0', '56318.0', '56424.0', '56938.0', '57163.0', '57558.0', '57783.0', '58178.0', '58403.0', '58798.0', '59023.0', '59418.0', '59643.0', '60038.0', '60263.0', '60658.0', '60883.0', '61278.0', '61503.0', '61898.0', '62123.0', '62518.0', '62743.0', '63138.0', '63363.0', '63758.0', '63983.0', '64378.0', '64603.0', '64998.0', '65223.0', '65618.0', '65843.0', '66238.0', '66463.0', '66858.0', '67083.0', '67478.0', '67703.0', '68098.0', '68323.0', '68718.0', '68943.0', '69338.0', '69563.0', '69979.0', '70183.0', '70690.0', '70778.0', '71170.0', '71392.0', '72012.0', '72632.0', '73275.0', '74175.0', '74696.0', '74775.0', '75296.0', '75896.0', '75975.0', '76496.0', '76575.0', '77096.0', '77175.0', '77696.0', '77775.0', '78296.0', '78375.0', '78896.0', '78975.0', '79496.0', '79575.0', '80096.0', '80175.0', '80696.0', '80775.0', '81296.0', '81375.0', '81896.0', '81975.0', '82496.0', '82575.0', '83096.0', '83175.0', '83696.0', '83775.0', '84596.0', '85155.0', '85796.0', '86175.0', '86996.0', '87375.0', '88575.0']\n"
     ]
    }
   ],
   "source": [
    "ReadSchedule = csv.reader(open('Schedule20210915.csv', 'r'),delimiter=',')\n",
    "for i,row in enumerate(ReadSchedule):\n",
    "    if i==2:\n",
    "        print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En premier lieu on a la route_id , puis la direction, puis le stop_id, puis toutes les arrivées classée par temps, toutes au format string\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok maintenant qu'on a le schedule sur la journée qui nous intéresse, on peut commencer à calculer les TimeGroup via cluster, on calcul le SWT sur chaque(cfr slide STIB, je ne fais pas de moyenne mais je calcul sur tous les intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime ~ 35min \n",
    "\n",
    "#DO NOT RUN THE CELL, OTHERWISE IT WILL WRITE OVER THE EXISTING FILE AND YOU'LL HAVE TO WAIT 35min\n",
    "\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "with open('TimeGroupWeekdayAllStopNewSWT.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            DataTemp = TroncatedScheduleRegularity(('20210915','wednesday'),route,stop)\n",
    "            IntervalTime = DataTemp[0]\n",
    "            ArrivalTime = DataTemp[1]\n",
    "            Data = pd.DataFrame({'ArrivalTime':ArrivalTime, 'TimeWaited':IntervalTime})\n",
    "            if len(Data)>6:\n",
    "                Clusters = Clustering(distance_measures['manhattan'],6,Data)[0]\n",
    "                Clusters.sort(key=lambda x: x[0])\n",
    "                row = [route,stop]\n",
    "                for cluster in Clusters:\n",
    "                    #MeanIntervalTimeInCluster = Data.iloc[cluster[0]:cluster[-1],1].mean()\n",
    "                    SWT = Data.iloc[cluster[0]:cluster[-1],1].values\n",
    "                    if sum(SWT)!=0:\n",
    "                        SWT = sum(SWT**2)/(2*sum(SWT))\n",
    "                    elif sum(SWT)==0:\n",
    "                        print('Problem with SWT on stop: '+str)\n",
    "                        SWT='Problem with SWT'\n",
    "                    #rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(MeanIntervalTimeInCluster)\n",
    "                    rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(SWT)\n",
    "                    row.append(rangeCluster)\n",
    "                writer.writerow(row)\n",
    "        k+=1\n",
    "        if k==5:\n",
    "            print(str(k*l)+' route encodées')\n",
    "            l+=1\n",
    "            k=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons au format d'une ligne de TimeGroupWeekdayAllStopNewSWT, que j'exporte en DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>Cluster1</th>\n",
       "      <th>Cluster2</th>\n",
       "      <th>Cluster3</th>\n",
       "      <th>Cluster4</th>\n",
       "      <th>Cluster5</th>\n",
       "      <th>Cluster6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>8161</td>\n",
       "      <td>19800.0::32447.0::176.4866371471495</td>\n",
       "      <td>32806.0::43817.0::167.70143492870767</td>\n",
       "      <td>44092.0::53848.0::117.4270192701927</td>\n",
       "      <td>54167.0::63983.0::168.94111654441727</td>\n",
       "      <td>64378.0::74775.0::223.9188708281235</td>\n",
       "      <td>75296.0::86996.0::264.5808547008547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8151</td>\n",
       "      <td>19879.0::29475.0::182.8805752396832</td>\n",
       "      <td>29785.0::39221.0::164.92528613819414</td>\n",
       "      <td>39671.0::50021.0::225.0</td>\n",
       "      <td>50471.0::60737.0::175.89976621858563</td>\n",
       "      <td>61047.0::71249.0::161.03420897863165</td>\n",
       "      <td>72389.0::83175.0::299.6196921935843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8141</td>\n",
       "      <td>19950.0::29549.0::182.9182727367434</td>\n",
       "      <td>29859.0::39294.0::164.90943296237413</td>\n",
       "      <td>39744.0::50094.0::225.0</td>\n",
       "      <td>50544.0::60810.0::175.89976621858563</td>\n",
       "      <td>61120.0::71320.0::161.00303921568627</td>\n",
       "      <td>72460.0::83246.0::299.6196921935843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>8131</td>\n",
       "      <td>20017.0::29621.0::182.98313202832153</td>\n",
       "      <td>29931.0::39363.0::164.86248939779475</td>\n",
       "      <td>39813.0::50163.0::225.0</td>\n",
       "      <td>50613.0::60881.0::175.92569146864042</td>\n",
       "      <td>61191.0::71387.0::160.9418399372303</td>\n",
       "      <td>72527.0::83313.0::299.6196921935843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>8121</td>\n",
       "      <td>20098.0::29705.0::183.02045383574477</td>\n",
       "      <td>30015.0::39446.0::164.84704697274944</td>\n",
       "      <td>39896.0::50246.0::225.0</td>\n",
       "      <td>50696.0::60964.0::175.92569146864042</td>\n",
       "      <td>61274.0::71468.0::160.91181086913872</td>\n",
       "      <td>72608.0::83394.0::299.6196921935843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   route_id stop_id                              Cluster1  \\\n",
       "0         2    8161   19800.0::32447.0::176.4866371471495   \n",
       "1         2    8151   19879.0::29475.0::182.8805752396832   \n",
       "2         2    8141   19950.0::29549.0::182.9182727367434   \n",
       "3         2    8131  20017.0::29621.0::182.98313202832153   \n",
       "4         2    8121  20098.0::29705.0::183.02045383574477   \n",
       "\n",
       "                               Cluster2                             Cluster3  \\\n",
       "0  32806.0::43817.0::167.70143492870767  44092.0::53848.0::117.4270192701927   \n",
       "1  29785.0::39221.0::164.92528613819414              39671.0::50021.0::225.0   \n",
       "2  29859.0::39294.0::164.90943296237413              39744.0::50094.0::225.0   \n",
       "3  29931.0::39363.0::164.86248939779475              39813.0::50163.0::225.0   \n",
       "4  30015.0::39446.0::164.84704697274944              39896.0::50246.0::225.0   \n",
       "\n",
       "                               Cluster4                              Cluster5  \\\n",
       "0  54167.0::63983.0::168.94111654441727   64378.0::74775.0::223.9188708281235   \n",
       "1  50471.0::60737.0::175.89976621858563  61047.0::71249.0::161.03420897863165   \n",
       "2  50544.0::60810.0::175.89976621858563  61120.0::71320.0::161.00303921568627   \n",
       "3  50613.0::60881.0::175.92569146864042   61191.0::71387.0::160.9418399372303   \n",
       "4  50696.0::60964.0::175.92569146864042  61274.0::71468.0::160.91181086913872   \n",
       "\n",
       "                              Cluster6  \n",
       "0  75296.0::86996.0::264.5808547008547  \n",
       "1  72389.0::83175.0::299.6196921935843  \n",
       "2  72460.0::83246.0::299.6196921935843  \n",
       "3  72527.0::83313.0::299.6196921935843  \n",
       "4  72608.0::83394.0::299.6196921935843  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Clusterdf = pd.read_csv('TimeGroupWeekdayAllStopNewSWT.csv')\n",
    "Clusterdf.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format d'une cellule: on a une string avec 3 nombre séparés par des '::' . Les deux premiers sont les ranges de temps déterminé par le Cluster1, ici dans la première ligne c'est entre 19800 et 32447 secondes après minuit. Le dernier nombre est le SWT calculé dans ce cluster, via les intervales, voir slides STIB"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nickel ! Maintenant qu'on a ça il suffit de venir chercher les données JSON de Mehdi pour la même date, et de les trier par Cluster, c'est l'objet de la prochaine cellule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 arrêt encodées\n",
      "1000 arrêt encodées\n",
      "1500 arrêt encodées\n",
      "2000 arrêt encodées\n",
      "2500 arrêt encodées\n",
      "3000 arrêt encodées\n",
      "3500 arrêt encodées\n"
     ]
    }
   ],
   "source": [
    "#Runtime ~ 10sec  \n",
    "\n",
    "#DO NOT RUN THE CELL, OTHERWISE IT WILL WRITE OVER THE EXISTING FILE AND YOU'LL HAVE TO WAIT 10 sec\n",
    "\n",
    "ReaderJson = csv.reader(open('stop_times_line_cleared2.csv', 'r'),delimiter=',')\n",
    "TimeGroupClusterdf = pd.read_csv('TimeGroupWeekdayAllStopNewSWT.csv')\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "#Fonction pour lire le CSV JSON\n",
    "\n",
    "with open('ClassifiedRegularityPointInJson.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for row in ReaderJson:\n",
    "        if len(row)>2:\n",
    "            route = int(FromLineIdtoRouteId(str((row[0]))))\n",
    "            stop = str(row[1])\n",
    "            RangeClusterInvolved = TimeGroupClusterdf[(TimeGroupClusterdf['route_id']==route) & (TimeGroupClusterdf['stop_id']==stop) ][['Cluster1','Cluster2','Cluster3','Cluster4','Cluster5','Cluster6']].values\n",
    "            \n",
    "            if len(RangeClusterInvolved)>0:\n",
    "                RangeClusterInvolved = [RangeClust.split('::') for RangeClust in RangeClusterInvolved[0]]\n",
    "                ArrivalTime = np.array(row[2].split(',')).astype(np.float)\n",
    "                IntervalTime = ArrivalTime[1:]-ArrivalTime[:-1]\n",
    "                RowToWrite=[route,stop]\n",
    "                for rangecluster in RangeClusterInvolved:\n",
    "                    borneinf = float(rangecluster[0])\n",
    "                    bornesup = float(rangecluster[1])\n",
    "                    swt = rangecluster[2]\n",
    "                    DataInCluster= str(rangecluster[2])  #We start writing the row with SWT factor that we'll need later\n",
    "                    for i,interval in enumerate(IntervalTime):\n",
    "                        if (borneinf<ArrivalTime[i]) & (ArrivalTime[i]<=bornesup):\n",
    "                            DataInCluster+= ','+str(interval)\n",
    "                    #DataInCluster = [IntervalTime[i] for i in range(len(IntervalTime))] #if (borneinf<ArrivalTime[i]) & (ArrivalTime[i]<=bornesup) ]\n",
    "                    RowToWrite.append(DataInCluster)\n",
    "                writer.writerow(RowToWrite)\n",
    "            \n",
    "        k+=1\n",
    "        if k==500:\n",
    "            print(str(k*l)+' arrêt encodées')\n",
    "            l+=1\n",
    "            k=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons encore une fois au format qu'on vient de créer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "94\n",
      "10\n",
      "101\n",
      "15\n",
      "1222\n",
      "230.0,1229.141000032425,546.6260001659393,479.14299988746643,1936.6419999599457,30.618000030517578,32.46199989318848,30.926000118255615,699.8210000991821,31.436999797821045,442.4830000400543,31.847000122070312,64.7189998626709,63.592000007629395,31.23300004005432,31.13100004196167,94.10800004005432,0.0,33.382999897003174,31.64300012588501,32.46199989318848,32.66600012779236,411.66100001335144,32.56399989128113,980.7139999866486,158.00799989700317,379.6080000400543,633.0550000667572,32.15499997138977,31.028000116348267,415.9609999656677,316.1180000305176\n"
     ]
    }
   ],
   "source": [
    "ReaderClassifiedJson = csv.reader(open('ClassifiedRegularityPointInJson.csv', 'r'),delimiter=',')\n",
    "for i,row in enumerate(ReaderClassifiedJson):\n",
    "    if row[1]=='6209':\n",
    "        print(row[0])\n",
    "        print(i)\n",
    "    if i==1223:\n",
    "        print(row[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chaque ligne, on a une liste qui contient la route_id, le stop_id, puis 6 différentes string qui correspondent au 6 clusters et dans chaque string on a les intervals time du JSON qui sont contenus dans ce cluster, et qui sont séparés par une ','\n",
    "ATTENTION: le premier éléments de chaque string de cluster correspond au SWT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant calculer les EWT !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excesswaitingtime(swt,ArrivalTimeJSONArray):\n",
    "    #both are given in second \n",
    "    #we give the EWT in second\n",
    "    #ArrivalTimeJSONArray = np.array(ArrivalTimeJSONList)\n",
    "    if swt == 'Problem with SWT':\n",
    "        print('flag')\n",
    "        return 'No EWT available'\n",
    "    elif np.float(swt) ==np.float(0):\n",
    "        return 'Problem with SWT = 0'\n",
    "    elif sum(ArrivalTimeJSONArray)==0:\n",
    "          return 'Problem with AWT = 0'\n",
    "    else:\n",
    "        awt = sum((ArrivalTimeJSONArray)**2)/(2*sum(ArrivalTimeJSONArray))\n",
    "        ewt = awt-np.float(swt)\n",
    "        return ewt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 arrêts encodés\n",
      "500 arrêts encodés\n",
      "1000 arrêts encodés\n",
      "1500 arrêts encodés\n",
      "2000 arrêts encodés\n"
     ]
    }
   ],
   "source": [
    "ReaderClassifiedJson = csv.reader(open('ClassifiedRegularityPointInJson.csv', 'r'),delimiter=',')\n",
    "\n",
    "header = ['route_id','stop_id','EWT1', 'EWT2', 'EWT3', 'EWT4','EWT5','EWT6']\n",
    "\n",
    "\n",
    "with open('EWTScore6clusterAllStop20210915.csv', 'w', encoding='UTF8',newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    \n",
    "    for i,row in enumerate(ReaderClassifiedJson):\n",
    "        route = row[0]\n",
    "        stop = row[1]\n",
    "        if i>0:\n",
    "            RowToWrite=[route,stop]\n",
    "            for IntervalInClusterReal in row[2:]:\n",
    "                ListOfData = np.array(IntervalInClusterReal.split(','))\n",
    "                swt = ListOfData[0]\n",
    "                if (ListOfData[0] == 'Problem with SWT' ):\n",
    "                    ewt = 'No EWT available'\n",
    "                else:\n",
    "                    ListOfData = ListOfData.astype(np.float)\n",
    "                    ewt = excesswaitingtime(swt,ListOfData[1:])\n",
    "                RowToWrite.append(ewt)\n",
    "            writer.writerow(RowToWrite)\n",
    "\n",
    "        if i%500==0:\n",
    "            print(str(i)+' arrêts encodés')   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>EWT1</th>\n",
       "      <th>EWT2</th>\n",
       "      <th>EWT3</th>\n",
       "      <th>EWT4</th>\n",
       "      <th>EWT5</th>\n",
       "      <th>EWT6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>40</td>\n",
       "      <td>5501</td>\n",
       "      <td>240.48242848801218</td>\n",
       "      <td>102.76864825488695</td>\n",
       "      <td>302.1294227846029</td>\n",
       "      <td>340.233225429478</td>\n",
       "      <td>367.49553356368006</td>\n",
       "      <td>175.65855506412697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>40</td>\n",
       "      <td>5502</td>\n",
       "      <td>381.81874053480885</td>\n",
       "      <td>103.3301532668072</td>\n",
       "      <td>476.18709519062656</td>\n",
       "      <td>260.8774506535701</td>\n",
       "      <td>440.4995594121988</td>\n",
       "      <td>184.23500256845455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>40</td>\n",
       "      <td>5503</td>\n",
       "      <td>207.29077775875422</td>\n",
       "      <td>249.36538784751093</td>\n",
       "      <td>278.45957270336044</td>\n",
       "      <td>429.9014994519142</td>\n",
       "      <td>414.8620341344198</td>\n",
       "      <td>217.23562428941534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>40</td>\n",
       "      <td>5504</td>\n",
       "      <td>107.5292856134117</td>\n",
       "      <td>388.7121030154504</td>\n",
       "      <td>156.42133757550934</td>\n",
       "      <td>137.23873747218576</td>\n",
       "      <td>503.85384498350106</td>\n",
       "      <td>445.57349163106045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>40</td>\n",
       "      <td>5507</td>\n",
       "      <td>460.03387252892094</td>\n",
       "      <td>764.3379881336159</td>\n",
       "      <td>555.472246469932</td>\n",
       "      <td>148.82556045647985</td>\n",
       "      <td>539.7705034754897</td>\n",
       "      <td>762.9262196041234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>40</td>\n",
       "      <td>5508</td>\n",
       "      <td>523.8765711501536</td>\n",
       "      <td>347.8594912515601</td>\n",
       "      <td>437.09481819961127</td>\n",
       "      <td>288.74075890835695</td>\n",
       "      <td>236.79888988678846</td>\n",
       "      <td>314.9108732604581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>40</td>\n",
       "      <td>5555</td>\n",
       "      <td>285.07839127503235</td>\n",
       "      <td>606.0749205927641</td>\n",
       "      <td>515.2591956168451</td>\n",
       "      <td>744.9958445061443</td>\n",
       "      <td>636.8203756364874</td>\n",
       "      <td>1675.0098784512036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>40</td>\n",
       "      <td>5556</td>\n",
       "      <td>676.7005974464603</td>\n",
       "      <td>814.5331435636829</td>\n",
       "      <td>585.042297387548</td>\n",
       "      <td>430.25243435232335</td>\n",
       "      <td>474.63750256058916</td>\n",
       "      <td>1666.6181879416467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>40</td>\n",
       "      <td>5559</td>\n",
       "      <td>70.3041591130991</td>\n",
       "      <td>279.13524944222695</td>\n",
       "      <td>605.1707968284647</td>\n",
       "      <td>567.312616205078</td>\n",
       "      <td>274.77815766424123</td>\n",
       "      <td>396.7111091329913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>40</td>\n",
       "      <td>5560</td>\n",
       "      <td>290.97203746259703</td>\n",
       "      <td>931.8802634735755</td>\n",
       "      <td>382.1444813488429</td>\n",
       "      <td>591.9712690186959</td>\n",
       "      <td>452.17696981331335</td>\n",
       "      <td>367.0935768164028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>40</td>\n",
       "      <td>5562</td>\n",
       "      <td>144.3058351009236</td>\n",
       "      <td>281.20139073227404</td>\n",
       "      <td>137.25616372264275</td>\n",
       "      <td>170.55915421891697</td>\n",
       "      <td>124.64946285285913</td>\n",
       "      <td>163.62964470774486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>40</td>\n",
       "      <td>5601</td>\n",
       "      <td>525.2704899833144</td>\n",
       "      <td>519.6840414226265</td>\n",
       "      <td>325.97211836497047</td>\n",
       "      <td>498.6319409971103</td>\n",
       "      <td>358.29707131000237</td>\n",
       "      <td>718.0396646315744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>40</td>\n",
       "      <td>5602</td>\n",
       "      <td>804.9573607708231</td>\n",
       "      <td>1698.9957741868768</td>\n",
       "      <td>1172.727840053989</td>\n",
       "      <td>258.14672631545864</td>\n",
       "      <td>419.1875849975464</td>\n",
       "      <td>788.3659675204992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>40</td>\n",
       "      <td>5603</td>\n",
       "      <td>1403.9696174626947</td>\n",
       "      <td>575.6445756647613</td>\n",
       "      <td>272.84420133286744</td>\n",
       "      <td>174.09062587354404</td>\n",
       "      <td>592.6906419411318</td>\n",
       "      <td>547.5036473873581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>40</td>\n",
       "      <td>5604</td>\n",
       "      <td>921.4631384413515</td>\n",
       "      <td>1534.8648490544474</td>\n",
       "      <td>1244.7403070620505</td>\n",
       "      <td>658.4627124516792</td>\n",
       "      <td>1839.1761539370427</td>\n",
       "      <td>1324.9483890036106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>40</td>\n",
       "      <td>5605</td>\n",
       "      <td>687.393363911312</td>\n",
       "      <td>791.2256313189018</td>\n",
       "      <td>326.9806102065826</td>\n",
       "      <td>409.48925583030143</td>\n",
       "      <td>297.15232533170075</td>\n",
       "      <td>621.7616676784078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>40</td>\n",
       "      <td>5655</td>\n",
       "      <td>308.39765640480925</td>\n",
       "      <td>422.00899137021077</td>\n",
       "      <td>63.19482615981954</td>\n",
       "      <td>745.9004736426616</td>\n",
       "      <td>288.8828597493172</td>\n",
       "      <td>1298.9856858209464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>40</td>\n",
       "      <td>5656</td>\n",
       "      <td>956.2030181638845</td>\n",
       "      <td>238.8075242031976</td>\n",
       "      <td>340.5715012567489</td>\n",
       "      <td>1188.7545293170488</td>\n",
       "      <td>738.3891753735718</td>\n",
       "      <td>1764.0064716265192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>40</td>\n",
       "      <td>5657</td>\n",
       "      <td>430.19042546518176</td>\n",
       "      <td>772.3236079473261</td>\n",
       "      <td>725.3797376463349</td>\n",
       "      <td>428.29935833069953</td>\n",
       "      <td>548.5811890328405</td>\n",
       "      <td>862.2589532990139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>40</td>\n",
       "      <td>5658</td>\n",
       "      <td>553.935821489631</td>\n",
       "      <td>2620.510431628338</td>\n",
       "      <td>2058.0986599692033</td>\n",
       "      <td>1009.4775919794018</td>\n",
       "      <td>271.87302091711706</td>\n",
       "      <td>2188.1369668529837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>40</td>\n",
       "      <td>5659</td>\n",
       "      <td>623.4709495186206</td>\n",
       "      <td>2505.7225177375503</td>\n",
       "      <td>1156.5807510351578</td>\n",
       "      <td>631.8885202304945</td>\n",
       "      <td>311.31993125366415</td>\n",
       "      <td>1093.5165337721623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>40</td>\n",
       "      <td>9551</td>\n",
       "      <td>1179.724834734224</td>\n",
       "      <td>943.3612838088341</td>\n",
       "      <td>434.8777785019861</td>\n",
       "      <td>947.3512294194794</td>\n",
       "      <td>659.3813466331871</td>\n",
       "      <td>995.782203161597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>40</td>\n",
       "      <td>9552</td>\n",
       "      <td>262.24910467675306</td>\n",
       "      <td>1165.1740563020044</td>\n",
       "      <td>622.6743130872206</td>\n",
       "      <td>64.49328671325165</td>\n",
       "      <td>474.1391837958257</td>\n",
       "      <td>260.65221734272313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>40</td>\n",
       "      <td>9553</td>\n",
       "      <td>407.141023415668</td>\n",
       "      <td>1021.2658385849604</td>\n",
       "      <td>648.5624862096844</td>\n",
       "      <td>353.438230613216</td>\n",
       "      <td>658.5956770634314</td>\n",
       "      <td>455.93168044387807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>40</td>\n",
       "      <td>9556</td>\n",
       "      <td>-129.26384589347794</td>\n",
       "      <td>-218.28583535993073</td>\n",
       "      <td>-143.7565283763113</td>\n",
       "      <td>-137.11856222351955</td>\n",
       "      <td>-160.61819586466163</td>\n",
       "      <td>-225.92655395151172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>40</td>\n",
       "      <td>9557</td>\n",
       "      <td>1617.5278883279263</td>\n",
       "      <td>Problem with AWT = 0</td>\n",
       "      <td>1408.4770474946147</td>\n",
       "      <td>2728.453462239092</td>\n",
       "      <td>Problem with AWT = 0</td>\n",
       "      <td>6703.8284882692915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>40</td>\n",
       "      <td>9575</td>\n",
       "      <td>281.5405284172447</td>\n",
       "      <td>270.39150314277634</td>\n",
       "      <td>339.4625956462651</td>\n",
       "      <td>275.19092221401445</td>\n",
       "      <td>421.71619164094096</td>\n",
       "      <td>887.7738283815243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>40</td>\n",
       "      <td>9577</td>\n",
       "      <td>591.4659557696712</td>\n",
       "      <td>327.1606130924974</td>\n",
       "      <td>363.25439659164556</td>\n",
       "      <td>314.6781768680762</td>\n",
       "      <td>371.27735631811646</td>\n",
       "      <td>952.4234097219569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>40</td>\n",
       "      <td>9578</td>\n",
       "      <td>530.2009330166651</td>\n",
       "      <td>741.8435881208927</td>\n",
       "      <td>522.2025791736107</td>\n",
       "      <td>341.06854007970753</td>\n",
       "      <td>415.53551371913073</td>\n",
       "      <td>809.9409274183797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     route_id  stop_id                 EWT1                  EWT2  \\\n",
       "914        40     5501   240.48242848801218    102.76864825488695   \n",
       "915        40     5502   381.81874053480885     103.3301532668072   \n",
       "916        40     5503   207.29077775875422    249.36538784751093   \n",
       "917        40     5504    107.5292856134117     388.7121030154504   \n",
       "918        40     5507   460.03387252892094     764.3379881336159   \n",
       "919        40     5508    523.8765711501536     347.8594912515601   \n",
       "920        40     5555   285.07839127503235     606.0749205927641   \n",
       "921        40     5556    676.7005974464603     814.5331435636829   \n",
       "922        40     5559     70.3041591130991    279.13524944222695   \n",
       "923        40     5560   290.97203746259703     931.8802634735755   \n",
       "924        40     5562    144.3058351009236    281.20139073227404   \n",
       "925        40     5601    525.2704899833144     519.6840414226265   \n",
       "926        40     5602    804.9573607708231    1698.9957741868768   \n",
       "927        40     5603   1403.9696174626947     575.6445756647613   \n",
       "928        40     5604    921.4631384413515    1534.8648490544474   \n",
       "929        40     5605     687.393363911312     791.2256313189018   \n",
       "930        40     5655   308.39765640480925    422.00899137021077   \n",
       "931        40     5656    956.2030181638845     238.8075242031976   \n",
       "932        40     5657   430.19042546518176     772.3236079473261   \n",
       "933        40     5658     553.935821489631     2620.510431628338   \n",
       "934        40     5659    623.4709495186206    2505.7225177375503   \n",
       "935        40     9551    1179.724834734224     943.3612838088341   \n",
       "936        40     9552   262.24910467675306    1165.1740563020044   \n",
       "937        40     9553     407.141023415668    1021.2658385849604   \n",
       "938        40     9556  -129.26384589347794   -218.28583535993073   \n",
       "939        40     9557   1617.5278883279263  Problem with AWT = 0   \n",
       "940        40     9575    281.5405284172447    270.39150314277634   \n",
       "941        40     9577    591.4659557696712     327.1606130924974   \n",
       "942        40     9578    530.2009330166651     741.8435881208927   \n",
       "\n",
       "                   EWT3                 EWT4                  EWT5  \\\n",
       "914   302.1294227846029     340.233225429478    367.49553356368006   \n",
       "915  476.18709519062656    260.8774506535701     440.4995594121988   \n",
       "916  278.45957270336044    429.9014994519142     414.8620341344198   \n",
       "917  156.42133757550934   137.23873747218576    503.85384498350106   \n",
       "918    555.472246469932   148.82556045647985     539.7705034754897   \n",
       "919  437.09481819961127   288.74075890835695    236.79888988678846   \n",
       "920   515.2591956168451    744.9958445061443     636.8203756364874   \n",
       "921    585.042297387548   430.25243435232335    474.63750256058916   \n",
       "922   605.1707968284647     567.312616205078    274.77815766424123   \n",
       "923   382.1444813488429    591.9712690186959    452.17696981331335   \n",
       "924  137.25616372264275   170.55915421891697    124.64946285285913   \n",
       "925  325.97211836497047    498.6319409971103    358.29707131000237   \n",
       "926   1172.727840053989   258.14672631545864     419.1875849975464   \n",
       "927  272.84420133286744   174.09062587354404     592.6906419411318   \n",
       "928  1244.7403070620505    658.4627124516792    1839.1761539370427   \n",
       "929   326.9806102065826   409.48925583030143    297.15232533170075   \n",
       "930   63.19482615981954    745.9004736426616     288.8828597493172   \n",
       "931   340.5715012567489   1188.7545293170488     738.3891753735718   \n",
       "932   725.3797376463349   428.29935833069953     548.5811890328405   \n",
       "933  2058.0986599692033   1009.4775919794018    271.87302091711706   \n",
       "934  1156.5807510351578    631.8885202304945    311.31993125366415   \n",
       "935   434.8777785019861    947.3512294194794     659.3813466331871   \n",
       "936   622.6743130872206    64.49328671325165     474.1391837958257   \n",
       "937   648.5624862096844     353.438230613216     658.5956770634314   \n",
       "938  -143.7565283763113  -137.11856222351955   -160.61819586466163   \n",
       "939  1408.4770474946147    2728.453462239092  Problem with AWT = 0   \n",
       "940   339.4625956462651   275.19092221401445    421.71619164094096   \n",
       "941  363.25439659164556    314.6781768680762    371.27735631811646   \n",
       "942   522.2025791736107   341.06854007970753    415.53551371913073   \n",
       "\n",
       "                    EWT6  \n",
       "914   175.65855506412697  \n",
       "915   184.23500256845455  \n",
       "916   217.23562428941534  \n",
       "917   445.57349163106045  \n",
       "918    762.9262196041234  \n",
       "919    314.9108732604581  \n",
       "920   1675.0098784512036  \n",
       "921   1666.6181879416467  \n",
       "922    396.7111091329913  \n",
       "923    367.0935768164028  \n",
       "924   163.62964470774486  \n",
       "925    718.0396646315744  \n",
       "926    788.3659675204992  \n",
       "927    547.5036473873581  \n",
       "928   1324.9483890036106  \n",
       "929    621.7616676784078  \n",
       "930   1298.9856858209464  \n",
       "931   1764.0064716265192  \n",
       "932    862.2589532990139  \n",
       "933   2188.1369668529837  \n",
       "934   1093.5165337721623  \n",
       "935     995.782203161597  \n",
       "936   260.65221734272313  \n",
       "937   455.93168044387807  \n",
       "938  -225.92655395151172  \n",
       "939   6703.8284882692915  \n",
       "940    887.7738283815243  \n",
       "941    952.4234097219569  \n",
       "942    809.9409274183797  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EWTWednesday = pd.read_csv('EWTScore6clusterAllStop20210915.csv')\n",
    "EWTWednesday[EWTWednesday['route_id']==40]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec7bd7830e1389ad0e956034e4c95e16eb9cab103064e78d4babc7287c4ec45a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
