{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtfs_functions as gtfs\n",
    "import matplotlib\n",
    "import geopandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import random\n",
    "from kneed import KneeLocator\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# cluster visualizer\n",
    "#%matplotlib inline\n",
    "#from yellowbrick.cluster import KElbowVisualizer \n",
    "\n",
    "# sklearn kmeans\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "# pyclustering kmeans\n",
    "from pyclustering.cluster.kmeans import kmeans\n",
    "from pyclustering.cluster.kmedians import kmedians\n",
    "from pyclustering.utils.metric import distance_metric\n",
    "from pyclustering.cluster.center_initializer import random_center_initializer\n",
    "from pyclustering.cluster.center_initializer import kmeans_plusplus_initializer\n",
    "from pyclustering.cluster.encoder import type_encoding\n",
    "from pyclustering.cluster.encoder import cluster_encoder\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the schedule\n",
    "\n",
    "path_gtfs ='C:/Users/Maison/Documents/INFO-H423/Projet Data Mining/GTFS3sep/gtfs3sept.zip'\n",
    "\n",
    "routes, stops, stop_times, trips, shapes = gtfs.import_gtfs(path_gtfs,busiest_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We import the calendar by hand \n",
    "\n",
    "calendardf = pd.read_table('calendar.txt',sep=',')          #export the calendar file into data frame\n",
    "calendarDatesdf = pd.read_table('calendar_dates.txt',sep=',')  #also export the exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FromDayToService(date):\n",
    "    '''Determine all the service_id concerned by a date, given in the format date=('20210907','tuesday')\n",
    "        it first take a look at every regular service_id then examine the exceptions. \n",
    "        Returns a list of service_id of type string'''\n",
    "\n",
    "    ListServiceId=[]\n",
    "    for i in range(len(calendardf)):\n",
    "        startdate,endate=calendardf.iloc[i,[8,9]]\n",
    "        if int(date[0]) in range(int(startdate),int(endate)+1):\n",
    "            if calendardf.loc[i,date[1]]==1:\n",
    "                #It appends every service_id which contains the date, and for which there is a '1'\n",
    "                # under right day in the week\n",
    "                ListServiceId.append(str(calendardf.iloc[i,0]))     \n",
    "\n",
    "    #Now we have to take a look a the exceptions\n",
    "    #We selections all the exceptions in calendarDatesdf that concerns the date in the input\n",
    "    ModifServiceId= calendarDatesdf[calendarDatesdf['date']==int(date[0])][['service_id','exception_type']]\n",
    "    #print('Number of service_id involved in modifications: '+ str(len(ModifServiceId)))\n",
    "    #for every modif we check the kind of exception\n",
    "    for modif in ModifServiceId.iterrows():  \n",
    "        service = str(modif[1]['service_id'])\n",
    "        exception = modif[1]['exception_type']\n",
    "        if exception == 1:\n",
    "            #if the exception is 1, it means that we should change to a 1 the cell related to the date in\n",
    "            # input, in the row equal to service in calendar\n",
    "            ListServiceId.append(service)\n",
    "            #print('ServiceId: '+str(service)+' correclty added' )\n",
    "        elif (exception == 2) & (service in ListServiceId):\n",
    "            #if the exception is 2, it means that we should change to a 0 the cell related to the date in\n",
    "            # input, in the row equal to service in calendar\n",
    "            #Since this service_id must have been selected in the first loop (in Calendar), we need to remove it\n",
    "            ListServiceId.remove(service)\n",
    "            #print('ServiceId: '+str(service)+' correclty removed' )\n",
    "        elif (exception == 2) & (service not in ListServiceId):\n",
    "            #if the exception is 2 but we haven't found the service id in the first loop, this is weird\n",
    "            #In principle this should not happend, but we're never too carefull\n",
    "            print('Warning : exception 2 but no service_id = ' +service+ ' found in calendar')\n",
    "    return (ListServiceId)\n",
    "\n",
    "def FromLineIdtoRouteId(LineId):\n",
    "    \n",
    "    '''Takes a lineid in argument a returns the correspondent routeid, since stop_times only \n",
    "        contains route_id'''\n",
    "\n",
    "    routeId = routes[routes['route_short_name']==LineId]['route_id'].iloc[0]\n",
    "    return routeId\n",
    "\n",
    "def ScheduledTime(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,routeid,stopId) with date in the format date=('20210907','tuesday')\n",
    "        and returns the schedule for that triplet. The schedule is composed as follows: if we are in a period of\n",
    "        punctuality then returns the (arrivaltime,true), and if we are in regularity, \n",
    "        returns (TimeOfWaitFromPreviousVehicle,False), all in one list '''\n",
    "\n",
    "    ListOfService = pd.Series(FromDayToService(date))  #List of service_id tha apply for that day\n",
    "    #RouteId = FromLineIdtoRouteId(lineId)               #We need the routeid to seek in the GTFS\n",
    "    #We select the relevant rows in GTFS stop_times\n",
    "    Scheduledf = stop_times[(stop_times['stop_id']==stopId)&(stop_times['route_id']==routeid)&(stop_times['service_id'].isin(ListOfService))].sort_values('arrival_time')\n",
    "    ArrivalTime = Scheduledf['arrival_time'].values\n",
    "    #print('Number of service_id involved: '+ str(len(ListOfService)))\n",
    "    #We compute every wainting time to determine punctuality of regularity (< or > 720 s)\n",
    "    #Schedule = list(ArrivalTime[1:]-ArrivalTime[:-1])\n",
    "    IntervalTime = list(ArrivalTime[1:]-ArrivalTime[:-1])\n",
    "    #Schedule.insert(0,ArrivalTime[0])\n",
    "    #True if punctuality, False if regularity\n",
    "    Punctuality = np.array(IntervalTime)>720 \n",
    "    #Ultimately, if we are a punctuality, we want the arrival time and if we are in regularity, we want the \n",
    "    #time bewteen two vehicles\n",
    "    for i,punctuality in enumerate(Punctuality):\n",
    "        if punctuality:\n",
    "            IntervalTime[i]=ArrivalTime[i]\n",
    "            #if (0<i<(len(Punctuality)-1)):\n",
    "                #if ~(Punctuality[i-1]) & ~(Punctuality[i+1]):\n",
    "                    #Punctuality[i]=False\n",
    "            #else:\n",
    "                \n",
    " \n",
    "    #Schedule = list(zip(Schedule,Punctuality))\n",
    "    #The format is a list of tuples\n",
    "    if len(IntervalTime)!=len(ArrivalTime[:-1]):\n",
    "        print('Attention: la longueur de Schedule et ArrivalTime ne match pas dans ScheduledTime ')\n",
    "    return IntervalTime,Punctuality,ArrivalTime[:-1]\n",
    "\n",
    "def RouteIdToLineId(routeId):\n",
    "\n",
    "    '''Takes a routeid in argument a returns the correspondent lineid'''\n",
    "\n",
    "    lineId = routes[routes['route_id']==routeId]['route_short_name'].iloc[0]\n",
    "    return lineId\n",
    "\n",
    "def TroncatedScheduleRegularity(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,routeid,stopId) in the format date=('20210907','tuesday') and returns the IntervalTime \n",
    "        and ArrivalTime cleared from the ponctuality point'''\n",
    "    ScheduleNonCleared = ScheduledTime(date,routeid,stopId)\n",
    "    TroncatedInterval = [intervaltime for i,intervaltime in enumerate(ScheduleNonCleared[0]) if not(ScheduleNonCleared[1][i])]\n",
    "    TroncatedArrival = [arrivaltime for i,arrivaltime in enumerate(ScheduleNonCleared[2]) if not(ScheduleNonCleared[1][i])]\n",
    "    if len(TroncatedInterval)!= len(TroncatedArrival):\n",
    "        print('Attention: la longueur de TroncatedInterval et TroncatedArrival ne match pas dans TroncatedScheduleRegularity ')\n",
    "    return TroncatedInterval,TroncatedArrival\n",
    "\n",
    "def ScheduledTimeCSV(date,routeid,stopId):\n",
    "\n",
    "    '''Takes a triplet (date,lineId,stopId) with date in the format date=('20210907','tuesday')\n",
    "        and returns the schedule for that triplet. THE DIFFERENCE WITH ScheduledTime IS THAT WE DONT\n",
    "        NEED THE PUNCTUALITY'''\n",
    "\n",
    "    ListOfService = pd.Series(FromDayToService(date))              #We need the routeid to seek in the GTFS\n",
    "    #We select the relevant rows in GTFS stop_times\n",
    "    Scheduledf = stop_times[(stop_times['stop_id']==stopId)&(stop_times['route_id']==routeid)&(stop_times['service_id'].isin(ListOfService))].sort_values('arrival_time')\n",
    "    directionId = Scheduledf['direction_id'].unique()\n",
    "    ArrivalTime = Scheduledf['arrival_time'].values\n",
    "    \n",
    "\n",
    "    return ArrivalTime,directionId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "StopTimesGroupTrip = stop_times.groupby('trip_id')[['stop_sequence']].mean().round()\n",
    "StopTimesGroupTrip['stop_sequence']=StopTimesGroupTrip['stop_sequence'].astype(int)\n",
    "\n",
    "StopTimesOnlyMeanSeq = pd.merge(stop_times, StopTimesGroupTrip, how='right', on= ['trip_id','stop_sequence'])\n",
    "StopTimesOnlyMeanSeq = StopTimesOnlyMeanSeq[['route_id','stop_sequence','stop_id','direction_id']]\n",
    "DicOfMiddleStop={}\n",
    "\n",
    "for route in StopTimesOnlyMeanSeq['route_id'].unique():\n",
    "    StopTimeMeanSeqRoute = StopTimesOnlyMeanSeq[StopTimesOnlyMeanSeq['route_id']==route]\n",
    "    directionIds = StopTimeMeanSeqRoute['direction_id'].unique()\n",
    "    for direction in directionIds:\n",
    "        #Ici je prends la première valeure que je trouve qui a la bonne route et direction\n",
    "        # car il peut y avoir plusieurs candidat Middle stop pour chaque (ligne,direction)\n",
    "        # ici je prend le premier parce que j'en ai très exactement rien à fouttre\n",
    "        stop = StopTimeMeanSeqRoute[StopTimeMeanSeqRoute['direction_id']==direction]['stop_id'].values[0]\n",
    "        value = str(route)+':'+str(direction)\n",
    "        if DicOfMiddleStop.get(stop) is None:\n",
    "            DicOfMiddleStop[stop]=value\n",
    "\n",
    "\n",
    "#Format du dico : 'middle_stop_id': 'routeid:direction'    Ex: '5510': '41:0'\n",
    "\n",
    "#Ici c'est juste pour lui dire quelle date prendre en exemple si on dit 'weekday', 'satuday', etc...\n",
    "DicOfWeek = {'weekday':('20210915','wednesday'),'saturday':('20210918','saturday'),'sunday':('20210919','sunday')}\n",
    "\n",
    "#liste des middle stop\n",
    "ListOfMiddleStop= list(DicOfMiddleStop.keys())\n",
    "\n",
    "def get_key(val):\n",
    "    for key, value in DicOfMiddleStop.items():\n",
    "        if val == value:\n",
    "            return key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ListOfStopId  = list(stop_times['stop_id'].unique())\n",
    "DicOfStopInRoute = {}\n",
    "for route in routes['route_id']:\n",
    "    ListOfStop = [stop for stop in stop_times[stop_times['route_id']==route]['stop_id'].unique()]\n",
    "    DicOfStopInRoute[route]=ListOfStop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo de Cluster de Gulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_measures = {'euclidean': 0, 'squared euclidean': 1, 'manhattan': 2, 'chebyshev': 3, \n",
    "                    'canberra': 5, 'chi-square': 6}\n",
    "\n",
    "routeidTram = ['3','10','6','11','12','25','76','41','40','15','26','9','42','14','16','7','75','8']\n",
    "routeidMetro = ['2','4','1','3']\n",
    "routeidBus = ['5', '13', '17', '18', '19', '20', '21', '22', '23', '24', '27', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '43', '44', '45', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '77', '78', '79', '80', '81', '82', '84', '85', '86', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97']\n",
    "\n",
    "\n",
    "\n",
    "def ClusteringOfData(dist_measure,Data,DataDelta,routeid,dayoftheweek):\n",
    "\n",
    "    #il faut sortir routeidMetro etc de la boucle\n",
    "    Clusters = []\n",
    "    routeidMetro = ['2','4','1','3']\n",
    "    routeidTram = ['3','10','6','11','12','25','76','41','40','15','26','9','42','14','16','7','75','8']\n",
    "\n",
    "    #delete if len(data)<10\n",
    "\n",
    "    if routeid in routeidMetro:\n",
    "        if dayoftheweek == 'weekday':\n",
    "            nclust = 4\n",
    "            nY = 1000\n",
    "            coefCent = 1.05\n",
    "        else:\n",
    "            nclust = 3\n",
    "            nY = 10000\n",
    "            coefCent = 1.05\n",
    "    elif routeid in routeidTram:\n",
    "        if dayoftheweek == 'weekday':\n",
    "            #print(len(Data))\n",
    "            nclust = len(Data)//35\n",
    "            nY = 1\n",
    "            coefCent = 1\n",
    "        else:\n",
    "            #print(len(Data))\n",
    "            nclust = len(Data)//25\n",
    "            nY = 1000\n",
    "            coefCent = 1\n",
    "    else:\n",
    "        if dayoftheweek == 'weekday':\n",
    "            #print(len(Data))\n",
    "            nclust = len(Data)//35\n",
    "            nY = 1000\n",
    "            coefCent = 1\n",
    "        else:\n",
    "            #print(len(Data))\n",
    "            nclust = len(Data)//25\n",
    "            nY = 1000\n",
    "            coefCent = 1\n",
    "    \n",
    "    if nclust == 1 or nclust == 0:\n",
    "        return(Clusters,nclust)\n",
    "\n",
    "    maxX = np.max(DataDelta.iloc[:,:1])*1\n",
    "    maxY = np.max(DataDelta.iloc[:,1:])*nY\n",
    "    DataDelta.iloc[:,:1] = DataDelta.iloc[:,:1]/maxX\n",
    "    DataDelta.iloc[:,1:] = DataDelta.iloc[:,1:]/maxY\n",
    "\n",
    "    initial_centers = kmeans_plusplus_initializer(DataDelta.values, nclust,amount_candidates = 4).initialize()\n",
    "    instanceKm = kmeans(DataDelta.values, initial_centers=initial_centers, metric=distance_metric(dist_measure))\n",
    "    instanceKm.process()\n",
    "    Centers = instanceKm.get_centers()\n",
    "\n",
    "    for center in Centers:\n",
    "        center[0] = center[0]*coefCent\n",
    "\n",
    "    instanceKmedians = kmedians(DataDelta.values, initial_medians=Centers,tolerance = 0.001)\n",
    "    instanceKmedians.process()\n",
    "    Clusters = instanceKmedians.get_clusters() \n",
    "\n",
    "\n",
    "    return(Clusters,nclust)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellule du Mercredi à exécuter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Runtime ~ 35min \n",
    "\n",
    "#Cellule pour mecredi 15/09\n",
    "\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "with open('TimeGroupWednesday20210915AllStop.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            DataTemp = TroncatedScheduleRegularity(('20210915','wednesday'),route,stop)\n",
    "            IntervalTime = DataTemp[0]\n",
    "            ArrivalTime = DataTemp[1]\n",
    "            Data = pd.DataFrame({'ArrivalTime':ArrivalTime, 'TimeWaited':IntervalTime})\n",
    "            DataDelta= pd.DataFrame({'ArrivalTime_i':ArrivalTime[:-1], 'TimeWaited':ArrivalTime[1:]})\n",
    "            if len(Data)>10:\n",
    "                #ClusteringOfData(dist_measure,nclust,Data,DataDelta,routeid,dayoftheweek):\n",
    "                ClustersOutput = ClusteringOfData(distance_measures['manhattan'],Data,DataDelta,route,'weekday')\n",
    "                Clusters = ClustersOutput[0]\n",
    "                NumCluster = ClustersOutput[1]\n",
    "                Clusters.sort(key=lambda x: x[0])\n",
    "                row = [route,stop]\n",
    "                for cluster in Clusters:\n",
    "                    #MeanIntervalTimeInCluster = Data.iloc[cluster[0]:cluster[-1],1].mean()\n",
    "                    #Warning we need to invert since every cluster is in other order\n",
    "                    SWT = Data.iloc[cluster[-1]:cluster[0],1].values\n",
    "                    if sum(SWT)!=0:\n",
    "                        SWT = sum(SWT**2)/(2*sum(SWT))\n",
    "                    elif sum(SWT)==0:\n",
    "                        print('Problem with SWT on stop: '+str(stop))\n",
    "                        SWT='Problem with SWT'\n",
    "                    #rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(MeanIntervalTimeInCluster)\n",
    "                    rangeCluster = str(Data.iloc[cluster[-1],0])+'::'+str(Data.iloc[cluster[0],0])+'::'+str(SWT)\n",
    "                    row.append(rangeCluster)\n",
    "                for i in range(NumCluster,6):\n",
    "                    row.append('0::0::0')\n",
    "                writer.writerow(row)\n",
    "        k+=1\n",
    "        if k%10==0:\n",
    "            print(str(k)+' routes encodées')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellule du Vendredi à exécuter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime ~ 35min \n",
    "\n",
    "#Cellule pour vendredi 17/09\n",
    "\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "with open('TimeGroupFriday20210917AllStop.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            DataTemp = TroncatedScheduleRegularity(('20210917','friday'),route,stop)\n",
    "            IntervalTime = DataTemp[0]\n",
    "            ArrivalTime = DataTemp[1]\n",
    "            Data = pd.DataFrame({'ArrivalTime':ArrivalTime, 'TimeWaited':IntervalTime})\n",
    "            DataDelta= pd.DataFrame({'ArrivalTime_i':ArrivalTime[:-1], 'TimeWaited':ArrivalTime[1:]})\n",
    "            if len(Data)>10:\n",
    "                #ClusteringOfData(dist_measure,nclust,Data,DataDelta,routeid,dayoftheweek):\n",
    "                ClustersOutput = ClusteringOfData(distance_measures['manhattan'],Data,DataDelta,route,'weekday')\n",
    "                Clusters = ClustersOutput[0]\n",
    "                NumCluster = ClustersOutput[1]\n",
    "                Clusters.sort(key=lambda x: x[0])\n",
    "                row = [route,stop]\n",
    "                for cluster in Clusters:\n",
    "                    #MeanIntervalTimeInCluster = Data.iloc[cluster[0]:cluster[-1],1].mean()\n",
    "                    #Warning we need to invert since every cluster is in other order\n",
    "                    SWT = Data.iloc[cluster[-1]:cluster[0],1].values\n",
    "                    if sum(SWT)!=0:\n",
    "                        SWT = sum(SWT**2)/(2*sum(SWT))\n",
    "                    elif sum(SWT)==0:\n",
    "                        print('Problem with SWT on stop: '+str(stop))\n",
    "                        SWT='Problem with SWT'\n",
    "                    #rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(MeanIntervalTimeInCluster)\n",
    "                    rangeCluster = str(Data.iloc[cluster[-1],0])+'::'+str(Data.iloc[cluster[0],0])+'::'+str(SWT)\n",
    "                    row.append(rangeCluster)\n",
    "                for i in range(NumCluster,6):\n",
    "                    row.append('0::0::0')\n",
    "                writer.writerow(row)\n",
    "        k+=1\n",
    "        if k%10==0:\n",
    "            print(str(k)+' routes encodées')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellule du samedi à exécuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem with SWT on stop: 8162\n"
     ]
    }
   ],
   "source": [
    "#Runtime ~ 35min \n",
    "\n",
    "#Cellule pour samedi 18/09\n",
    "\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "with open('TimeGroupSaturday20210918AllStop.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            DataTemp = TroncatedScheduleRegularity(('20210918','saturday'),route,stop)\n",
    "            IntervalTime = DataTemp[0]\n",
    "            ArrivalTime = DataTemp[1]\n",
    "            Data = pd.DataFrame({'ArrivalTime':ArrivalTime, 'TimeWaited':IntervalTime})\n",
    "            DataDelta= pd.DataFrame({'ArrivalTime_i':ArrivalTime[:-1], 'TimeWaited':ArrivalTime[1:]})\n",
    "            if len(Data)>10:\n",
    "                #ClusteringOfData(dist_measure,nclust,Data,DataDelta,routeid,dayoftheweek):\n",
    "                ClustersOutput = ClusteringOfData(distance_measures['manhattan'],Data,DataDelta,route,'saturday')\n",
    "                Clusters = ClustersOutput[0]\n",
    "                NumCluster = ClustersOutput[1]\n",
    "                Clusters.sort(key=lambda x: x[0])\n",
    "                row = [route,stop]\n",
    "                for cluster in Clusters:\n",
    "                    #MeanIntervalTimeInCluster = Data.iloc[cluster[0]:cluster[-1],1].mean()\n",
    "                    #Warning we need to invert since every cluster is in other order\n",
    "                    SWT = Data.iloc[cluster[-1]:cluster[0],1].values\n",
    "                    if sum(SWT)!=0:\n",
    "                        SWT = sum(SWT**2)/(2*sum(SWT))\n",
    "                    elif sum(SWT)==0:\n",
    "                        print('Problem with SWT on stop: '+str(stop))\n",
    "                        SWT='Problem with SWT'\n",
    "                    #rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(MeanIntervalTimeInCluster)\n",
    "                    rangeCluster = str(Data.iloc[cluster[-1],0])+'::'+str(Data.iloc[cluster[0],0])+'::'+str(SWT)\n",
    "                    row.append(rangeCluster)\n",
    "                for i in range(NumCluster,6):\n",
    "                    row.append('0::0::0')\n",
    "                writer.writerow(row)\n",
    "        k+=1\n",
    "        if k%10==0:\n",
    "            print(str(k)+' routes encodées')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellule du Dimanche à exécuter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Runtime ~ 35min \n",
    "\n",
    "#Cellule pour dimanche 19/09\n",
    "\n",
    "header = ['route_id','stop_id','Cluster1', 'Cluster2', 'Cluster3', 'Cluster4','Cluster5','Cluster6']\n",
    "\n",
    "with open('TimeGroupSunday20210919AllStop.csv', 'w', encoding='UTF8',newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # write the header\n",
    "    writer.writerow(header)\n",
    "    # write the data\n",
    "    k=0\n",
    "    l=1\n",
    "    for route in DicOfStopInRoute:\n",
    "        for stop in DicOfStopInRoute[route]:\n",
    "            DataTemp = TroncatedScheduleRegularity(('20210919','sunday'),route,stop)\n",
    "            IntervalTime = DataTemp[0]\n",
    "            ArrivalTime = DataTemp[1]\n",
    "            Data = pd.DataFrame({'ArrivalTime':ArrivalTime, 'TimeWaited':IntervalTime})\n",
    "            DataDelta= pd.DataFrame({'ArrivalTime_i':ArrivalTime[:-1], 'TimeWaited':ArrivalTime[1:]})\n",
    "            if len(Data)>10:\n",
    "                #ClusteringOfData(dist_measure,nclust,Data,DataDelta,routeid,dayoftheweek):\n",
    "                ClustersOutput = ClusteringOfData(distance_measures['manhattan'],Data,DataDelta,route,'sunday')\n",
    "                Clusters = ClustersOutput[0]\n",
    "                NumCluster = ClustersOutput[1]\n",
    "                Clusters.sort(key=lambda x: x[0])\n",
    "                row = [route,stop]\n",
    "                for cluster in Clusters:\n",
    "                    #MeanIntervalTimeInCluster = Data.iloc[cluster[0]:cluster[-1],1].mean()\n",
    "                    #Warning we need to invert since every cluster is in other order\n",
    "                    SWT = Data.iloc[cluster[-1]:cluster[0],1].values\n",
    "                    if sum(SWT)!=0:\n",
    "                        SWT = sum(SWT**2)/(2*sum(SWT))\n",
    "                    elif sum(SWT)==0:\n",
    "                        print('Problem with SWT on stop: '+str)\n",
    "                        SWT='Problem with SWT'\n",
    "                    #rangeCluster = str(Data.iloc[cluster[0],0])+'::'+str(Data.iloc[cluster[-1],0])+'::'+str(MeanIntervalTimeInCluster)\n",
    "                    rangeCluster = str(Data.iloc[cluster[-1],0])+'::'+str(Data.iloc[cluster[0],0])+'::'+str(SWT)\n",
    "                    row.append(rangeCluster)\n",
    "                for i in range(NumCluster,6):\n",
    "                    row.append('0::0::0')\n",
    "                writer.writerow(row)\n",
    "        k+=1\n",
    "        if k%10==0:\n",
    "            print(str(k)+' route encodées')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ec7bd7830e1389ad0e956034e4c95e16eb9cab103064e78d4babc7287c4ec45a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
